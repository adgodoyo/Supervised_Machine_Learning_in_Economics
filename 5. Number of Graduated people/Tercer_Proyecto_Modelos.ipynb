{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regresion Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo construira y evaluara un modelo de regresión lineal para predecir la cantidad de graduados (GRADUADOS) en función de variables relacionadas con indicadores educativos, demográficos y económicos. Se enfoca en preparar los datos, eliminar valores atípicos, escalar variables, codificar categorías y evaluar el modelo mediante validación cruzada.\n",
    "\n",
    "Pasos desarrollados  \n",
    "\n",
    "1. Carga y preprocesamiento de datos  \n",
    "Se cargaron los datos desde un archivo Excel (Graduados_total.xlsx).  \n",
    "Se eliminó los valores atípicos de la variable GRADUADOS utilizando el método de rango intercuartílico (IQR).  \n",
    "\n",
    "2. Selección de variables  \n",
    "Variable objetivo: GRADUADOS.  \n",
    "Variables predictoras: Incluyen datos numéricos como DOCENTES, MATRICULADOS, VIOLENCIA y categóricos como AREA_CON y AÑO.  \n",
    "\n",
    "3. Preparación para el modelado  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Las variables numéricas fueron escaladas con RobustScaler, mientras que las categóricas fueron codificadas con OneHotEncoder.  \n",
    "\n",
    "4. Modelo y validación cruzada  \n",
    "Se usó un modelo de regresión lineal (LinearRegression) con un pipeline que incluye preprocesamiento de los datos.  \n",
    "Se aplicó validación cruzada con 10 divisiones para medir la estabilidad del modelo.  \n",
    "\n",
    "5. Evaluación  \n",
    "Se calcularon métricas como R², MSE (Error Cuadrático Medio) y MAE (Error Absoluto Medio) tanto en la validación cruzada como en el conjunto de prueba.  \n",
    "\n",
    "Resultados:\n",
    "\n",
    "En la validación cruzada, se obtuvo el promedio de R², MSE y MAE para evaluar la generalización del modelo en los datos de entrenamiento.  \n",
    "En el conjunto de prueba, se calcularon las métricas para evaluar el desempeño en datos no vistos durante el entrenamiento.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8321\n",
      "  Fold 2: 0.8147\n",
      "  Fold 3: 0.8776\n",
      "  Fold 4: 0.8151\n",
      "  Fold 5: 0.8612\n",
      "  Fold 6: 0.7765\n",
      "  Fold 7: 0.8284\n",
      "  Fold 8: 0.8446\n",
      "  Fold 9: 0.8747\n",
      "  Fold 10: 0.8315\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2300\n",
      "  Fold 2: 0.2054\n",
      "  Fold 3: 0.1470\n",
      "  Fold 4: 0.1930\n",
      "  Fold 5: 0.1995\n",
      "  Fold 6: 0.2712\n",
      "  Fold 7: 0.2103\n",
      "  Fold 8: 0.1721\n",
      "  Fold 9: 0.1237\n",
      "  Fold 10: 0.2232\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2829\n",
      "  Fold 2: 0.2837\n",
      "  Fold 3: 0.2418\n",
      "  Fold 4: 0.2333\n",
      "  Fold 5: 0.2669\n",
      "  Fold 6: 0.2866\n",
      "  Fold 7: 0.2458\n",
      "  Fold 8: 0.2580\n",
      "  Fold 9: 0.2429\n",
      "  Fold 10: 0.2794\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8356\n",
      "  Promedio MSE: 0.1975\n",
      "  Promedio MAE: 0.2621\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de testeo: 0.8288\n",
      "MSE en el conjunto de testeo: 0.2251\n",
      "MAE en el conjunto de testeo: 0.2701\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx')\n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión lineal\n",
    "modelo = make_pipeline(preprocesador, LinearRegression())\n",
    "\n",
    "# Configuramos la validación cruzada\n",
    "cv_folds = 10\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializamos listas para las métricas de cada fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "# Validación cruzada personalizada\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y_train_scaled[train_idx], y_train_scaled[val_idx]\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    modelo.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_pred_cv = modelo.predict(X_val_cv)\n",
    "    \n",
    "    # Calculamos las métricas\n",
    "    r2_scores.append(modelo.score(X_val_cv, y_val_cv))\n",
    "    mse_scores.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "modelo.fit(X_train, y_train_scaled)\n",
    "y_pred_test_scaled = modelo.predict(X_test)\n",
    "\n",
    "# Métricas en el conjunto de prueba\n",
    "r2_test = modelo.score(X_test, y_test_scaled)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "# Resultados de validación cruzada\n",
    "print(\"Resultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Resultados en el conjunto de prueba\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de testeo: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de testeo: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de testeo: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Regresion Polinomica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del código es construir y evaluar un modelo de regresión lineal para predecir la cantidad de graduados (GRADUADOS) a partir de indicadores educativos, demográficos y económicos. En esta versión, se incorpora un enfoque de características polinómicas para mejorar la capacidad del modelo de capturar relaciones no lineales entre las variables predictoras y la variable objetivo.  \n",
    "\n",
    "Pasos desarrollados: \n",
    "\n",
    "1. Carga y preprocesamiento de datos  \n",
    "Se cargaron los datos desde un archivo Excel (Graduados_total.xlsx).  \n",
    "Se eliminaron los valores atípicos de la variable GRADUADOS mediante el rango intercuartílico (IQR).  \n",
    "\n",
    "2. Selección de variables  \n",
    "Variable objetivo: GRADUADOS.  \n",
    "Variables predictoras: Incluyen datos numéricos como DOCENTES , MATRÍCULADOS, VIOLENCIA y categóricos como AREA_CON y AÑO.  \n",
    "\n",
    "3. Preparación para el modelado  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Las variables numéricas fueron escaladas con RobustScaler. Se aplicaron características polinómicas de segundo grado para capturar interacciones no lineales en las variables numéricas. Las variables categóricas fueron codificadas con OneHotEncoder.  \n",
    "\n",
    "4. Modelo y validación cruzada  \n",
    "Se utilizó un modelo de regresión lineal (LinearRegression) con un pipeline que incluye escalamiento, expansión polinómica y codificación.  \n",
    "Se realizó validación cruzada con 10 divisiones para medir la estabilidad del modelo y evaluar su generalización en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación  \n",
    "Se calcularon métricas como R², MSE (Error Cuadrático Medio) y MAE (Error Absoluto Medio) tanto en la validación cruzada como en el conjunto de prueba.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "En la validación cruzada, se calculó el promedio de R², MSE y MAE, lo que permitió evaluar el desempeño del modelo en diferentes divisiones del conjunto de entrenamiento.  \n",
    "En el conjunto de prueba, se midieron las métricas de desempeño para evaluar la capacidad predictiva del modelo en datos no utilizados durante el entrenamiento.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.7142\n",
      "  Fold 2: 0.8265\n",
      "  Fold 3: 0.7832\n",
      "  Fold 4: 0.8084\n",
      "  Fold 5: 0.8732\n",
      "  Fold 6: 0.8123\n",
      "  Fold 7: 0.9140\n",
      "  Fold 8: 0.8813\n",
      "  Fold 9: 0.8446\n",
      "  Fold 10: 0.8021\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.3917\n",
      "  Fold 2: 0.1924\n",
      "  Fold 3: 0.2604\n",
      "  Fold 4: 0.2000\n",
      "  Fold 5: 0.1822\n",
      "  Fold 6: 0.2278\n",
      "  Fold 7: 0.1053\n",
      "  Fold 8: 0.1314\n",
      "  Fold 9: 0.1534\n",
      "  Fold 10: 0.2621\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2845\n",
      "  Fold 2: 0.2656\n",
      "  Fold 3: 0.2298\n",
      "  Fold 4: 0.2383\n",
      "  Fold 5: 0.2431\n",
      "  Fold 6: 0.2568\n",
      "  Fold 7: 0.2092\n",
      "  Fold 8: 0.2370\n",
      "  Fold 9: 0.2459\n",
      "  Fold 10: 0.2727\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8260\n",
      "  Promedio MSE: 0.2107\n",
      "  Promedio MAE: 0.2483\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de testeo: 0.8408\n",
      "MSE en el conjunto de testeo: 0.2093\n",
      "MAE en el conjunto de testeo: 0.2539\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (PolynomialFeatures(degree=2, include_bias=False), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión lineal\n",
    "modelo = make_pipeline(preprocesador, LinearRegression())\n",
    "\n",
    "# Configuramos la validación cruzada\n",
    "cv_folds = 10\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Inicializamos listas para las métricas de cada fold\n",
    "r2_scores = []\n",
    "mse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "# Validación cruzada personalizada\n",
    "for train_idx, val_idx in kf.split(X_train):\n",
    "    X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y_train_scaled[train_idx], y_train_scaled[val_idx]\n",
    "    \n",
    "    # Entrenamos el modelo\n",
    "    modelo.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_pred_cv = modelo.predict(X_val_cv)\n",
    "    \n",
    "    # Calculamos las métricas\n",
    "    r2_scores.append(modelo.score(X_val_cv, y_val_cv))\n",
    "    mse_scores.append(mean_squared_error(y_val_cv, y_pred_cv))\n",
    "    mae_scores.append(mean_absolute_error(y_val_cv, y_pred_cv))\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "modelo.fit(X_train, y_train_scaled)\n",
    "y_pred_test_scaled = modelo.predict(X_test)\n",
    "\n",
    "# Métricas en el conjunto de prueba\n",
    "r2_test = modelo.score(X_test, y_test_scaled)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "# Resultados de validación cruzada\n",
    "print(\"Resultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Resultados en el conjunto de prueba\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de testeo: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de testeo: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de testeo: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regresion Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código busca predecir la cantidad de graduados (GRADUADOS) mediante un modelo de regresión basado en Lasso, que incluye selección de características y ajuste de hiperparámetros mediante búsqueda aleatoria (RandomizedSearchCV). Este enfoque optimiza el modelo y mejora la interpretabilidad al seleccionar únicamente las características relevantes.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Selección de características  \n",
    "Se utilizó el modelo de Lasso para seleccionar automáticamente las variables predictoras más importantes eliminando aquellas con coeficientes cero. Esto asegura que el modelo sea más sencillo y enfocado en las variables relevantes.  \n",
    "\n",
    "2. Preparación de los datos  \n",
    "Se eliminaron valores atípicos de la variable GRADUADOS utilizando el rango intercuartílico (IQR).  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Se escaló la variable objetivo GRADUADOS utilizando RobustScaler para reducir el impacto de valores extremos.  \n",
    "\n",
    "3. Ajuste de hiperparámetros  \n",
    "Se configuró un pipeline que incluye escalado de las características seleccionadas y el modelo Lasso.  \n",
    "Se realizó una búsqueda aleatoria de hiperparámetros (`alpha`, `fit_intercept`, `max_iter`) con 50 iteraciones y validación cruzada de 10 folds.  \n",
    "\n",
    "4. Evaluación del modelo  \n",
    "Se utilizó validación cruzada con 10 folds para medir la estabilidad y generalización del modelo sobre el conjunto de entrenamiento.  \n",
    "Se evaluó el modelo final ajustado en el conjunto de prueba para calcular métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados  \n",
    "\n",
    "- Validación cruzada  \n",
    "Se obtuvieron métricas de R², MSE y MAE en cada fold para evaluar el desempeño del modelo en los datos de entrenamiento. Se calcularon los promedios de estas métricas para validar la consistencia del modelo.  \n",
    "\n",
    "- Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no vistos durante el entrenamiento, logrando métricas finales que reflejan su capacidad de generalización.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por Lasso: ['AÑO', 'COD_DEP', 'DOCENTES', 'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB', 'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%', 'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS']\n",
      "  Fold 1: R²=0.8293, MSE=0.2339, MAE=0.2795\n",
      "  Fold 2: R²=0.8114, MSE=0.2091, MAE=0.2793\n",
      "  Fold 3: R²=0.8805, MSE=0.1435, MAE=0.2354\n",
      "  Fold 4: R²=0.8095, MSE=0.1989, MAE=0.2362\n",
      "  Fold 5: R²=0.8584, MSE=0.2036, MAE=0.2629\n",
      "  Fold 6: R²=0.7739, MSE=0.2744, MAE=0.2825\n",
      "  Fold 7: R²=0.8270, MSE=0.2120, MAE=0.2452\n",
      "  Fold 8: R²=0.8466, MSE=0.1698, MAE=0.2557\n",
      "  Fold 9: R²=0.8788, MSE=0.1196, MAE=0.2310\n",
      "  Fold 10: R²=0.8254, MSE=0.2313, MAE=0.2805\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8293\n",
      "  Fold 2: 0.8114\n",
      "  Fold 3: 0.8805\n",
      "  Fold 4: 0.8095\n",
      "  Fold 5: 0.8584\n",
      "  Fold 6: 0.7739\n",
      "  Fold 7: 0.8270\n",
      "  Fold 8: 0.8466\n",
      "  Fold 9: 0.8788\n",
      "  Fold 10: 0.8254\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2339\n",
      "  Fold 2: 0.2091\n",
      "  Fold 3: 0.1435\n",
      "  Fold 4: 0.1989\n",
      "  Fold 5: 0.2036\n",
      "  Fold 6: 0.2744\n",
      "  Fold 7: 0.2120\n",
      "  Fold 8: 0.1698\n",
      "  Fold 9: 0.1196\n",
      "  Fold 10: 0.2313\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2795\n",
      "  Fold 2: 0.2793\n",
      "  Fold 3: 0.2354\n",
      "  Fold 4: 0.2362\n",
      "  Fold 5: 0.2629\n",
      "  Fold 6: 0.2825\n",
      "  Fold 7: 0.2452\n",
      "  Fold 8: 0.2557\n",
      "  Fold 9: 0.2310\n",
      "  Fold 10: 0.2805\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8341\n",
      "  Promedio MSE: 0.1996\n",
      "  Promedio MAE: 0.2588\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8256\n",
      "MSE en el conjunto de test: 0.2293\n",
      "MAE en el conjunto de test: 0.2683\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Verificamos si la columna 'GRADUADOS' está en el DataFrame antes de proceder\n",
    "try:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number').drop(columns=['GRADUADOS'])\n",
    "except KeyError:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number')\n",
    "\n",
    "# Selección de características con Lasso\n",
    "scaler = StandardScaler()\n",
    "lasso = Lasso(alpha=0.1, random_state=42)\n",
    "x_scaled = scaler.fit_transform(x_numeric)\n",
    "lasso.fit(x_scaled, Graduados_total['GRADUADOS'])\n",
    "\n",
    "# Máscara de características seleccionadas por Lasso\n",
    "coeff_mask = np.array([coef != 0 for coef in lasso.coef_])\n",
    "selected_features = x_numeric.columns[coeff_mask].tolist()\n",
    "\n",
    "print(\"Características seleccionadas por Lasso:\", selected_features)\n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "x = Graduados_total[selected_features]\n",
    "y = Graduados_total['GRADUADOS']\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), selected_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Configuramos el pipeline con Lasso\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    Lasso(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para Lasso\n",
    "param_distributions = {\n",
    "    'lasso__alpha': uniform(0.01, 1.0),\n",
    "    'lasso__fit_intercept': [True, False],\n",
    "    'lasso__max_iter': randint(1000, 5000)\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=10,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regresion Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es construir un modelo de regresión Ridge para predecir la cantidad de graduados (GRADUADOS) basado en variables seleccionadas automáticamente y con ajuste de hiperparámetros para maximizar el desempeño predictivo. Ridge permite manejar problemas de multicolinealidad y regularización para evitar el sobreajuste.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Selección de características  \n",
    "Se usó Ridge con regularización para identificar las variables predictoras más relevantes. Aunque Ridge no anula coeficientes como Lasso, permite reducir la influencia de variables menos importantes.  \n",
    "\n",
    "2. Preparación de los datos  \n",
    "Se eliminaron valores atípicos de la variable GRADUADOS utilizando el rango intercuartílico (IQR).  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Se escaló la variable objetivo GRADUADOS utilizando RobustScaler para reducir el impacto de valores extremos.  \n",
    "\n",
    "3. Ajuste de hiperparámetros  \n",
    "Se configuró un pipeline que incluye el preprocesamiento y el modelo Ridge.  \n",
    "Se realizó una búsqueda aleatoria de hiperparámetros, incluyendo `alpha` (intensidad de regularización), `solver` (algoritmo de optimización), `fit_intercept` (ajuste del intercepto) y `max_iter` (iteraciones máximas).  \n",
    "\n",
    "4. Validación cruzada  \n",
    "Se utilizó validación cruzada con 10 folds para medir la estabilidad y generalización del modelo sobre el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final ajustado fue evaluado en el conjunto de prueba mediante métricas como R², MSE y MAE, escalando las variables objetivo para una evaluación más consistente.  \n",
    "\n",
    "Resultados: \n",
    "\n",
    "- Validación cruzada  \n",
    "Se obtuvieron métricas de R², MSE y MAE en cada fold para evaluar el desempeño del modelo en los datos de entrenamiento. Los promedios de estas métricas muestran el desempeño general del modelo en diferentes particiones.  \n",
    "\n",
    "- Conjunto de prueba  \n",
    "El modelo ajustado fue evaluado en datos no utilizados durante el entrenamiento. Los resultados reflejan la capacidad de generalización del modelo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por Ridge: ['AÑO', 'COD_DEP', 'COD_MUN', 'DOCENTES', 'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB', 'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%', 'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS']\n",
      "  Fold 1: R²=0.8326, MSE=0.2294, MAE=0.2737\n",
      "  Fold 2: R²=0.8117, MSE=0.2088, MAE=0.2812\n",
      "  Fold 3: R²=0.8806, MSE=0.1434, MAE=0.2351\n",
      "  Fold 4: R²=0.8140, MSE=0.1941, MAE=0.2334\n",
      "  Fold 5: R²=0.8585, MSE=0.2033, MAE=0.2628\n",
      "  Fold 6: R²=0.7769, MSE=0.2707, MAE=0.2807\n",
      "  Fold 7: R²=0.8244, MSE=0.2152, MAE=0.2429\n",
      "  Fold 8: R²=0.8456, MSE=0.1709, MAE=0.2554\n",
      "  Fold 9: R²=0.8764, MSE=0.1220, MAE=0.2336\n",
      "  Fold 10: R²=0.8273, MSE=0.2288, MAE=0.2740\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8326\n",
      "  Fold 2: 0.8117\n",
      "  Fold 3: 0.8806\n",
      "  Fold 4: 0.8140\n",
      "  Fold 5: 0.8585\n",
      "  Fold 6: 0.7769\n",
      "  Fold 7: 0.8244\n",
      "  Fold 8: 0.8456\n",
      "  Fold 9: 0.8764\n",
      "  Fold 10: 0.8273\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2294\n",
      "  Fold 2: 0.2088\n",
      "  Fold 3: 0.1434\n",
      "  Fold 4: 0.1941\n",
      "  Fold 5: 0.2033\n",
      "  Fold 6: 0.2707\n",
      "  Fold 7: 0.2152\n",
      "  Fold 8: 0.1709\n",
      "  Fold 9: 0.1220\n",
      "  Fold 10: 0.2288\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2737\n",
      "  Fold 2: 0.2812\n",
      "  Fold 3: 0.2351\n",
      "  Fold 4: 0.2334\n",
      "  Fold 5: 0.2628\n",
      "  Fold 6: 0.2807\n",
      "  Fold 7: 0.2429\n",
      "  Fold 8: 0.2554\n",
      "  Fold 9: 0.2336\n",
      "  Fold 10: 0.2740\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8348\n",
      "  Promedio MSE: 0.1987\n",
      "  Promedio MAE: 0.2573\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8254\n",
      "MSE en el conjunto de test: 0.2296\n",
      "MAE en el conjunto de test: 0.2665\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Verificamos si la columna 'GRADUADOS' está en el DataFrame antes de proceder\n",
    "try:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number').drop(columns=['GRADUADOS'])\n",
    "except KeyError:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number')\n",
    "\n",
    "# Selección de características con Ridge\n",
    "scaler = StandardScaler()\n",
    "ridge_selector = Ridge(alpha=0.1, random_state=42)\n",
    "x_scaled = scaler.fit_transform(x_numeric)\n",
    "ridge_selector.fit(x_scaled, Graduados_total['GRADUADOS'])\n",
    "\n",
    "# Máscara de características seleccionadas por Ridge (si se desea mantener la selección)\n",
    "coeff_mask = np.array([coef != 0 for coef in ridge_selector.coef_])\n",
    "selected_features = x_numeric.columns[coeff_mask].tolist()\n",
    "\n",
    "print(\"Características seleccionadas por Ridge:\", selected_features)\n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "x = Graduados_total[selected_features]\n",
    "y = Graduados_total['GRADUADOS']\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), selected_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Configuramos el pipeline con Ridge\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    Ridge(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para Ridge\n",
    "param_distributions = {\n",
    "    'ridge__alpha': uniform(0.01, 10.0),\n",
    "    'ridge__fit_intercept': [True, False],\n",
    "    'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'],\n",
    "    'ridge__max_iter': randint(1000, 5000)\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=10,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Regresion Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del modelo es predecir la cantidad de graduados (GRADUADOS) utilizando ElasticNet, un modelo de regresión que combina las propiedades de Lasso y Ridge para realizar selección de características y regularización. Este enfoque equilibra la simplicidad del modelo y la reducción de multicolinealidad, buscando maximizar el desempeño predictivo.\n",
    "\n",
    "Pasos desarrollados:\n",
    "\n",
    "1. Selección de características  \n",
    "Se utilizó ElasticNet con una combinación de penalización L1 (Lasso) y L2 (Ridge) para identificar las variables más relevantes. Las características seleccionadas se basan en los coeficientes no nulos del modelo.  \n",
    "\n",
    "2. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS mediante el rango intercuartílico (IQR).  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Se escaló la variable objetivo GRADUADOS utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "3. Configuración del modelo y ajuste de hiperparámetros  \n",
    "Se creó un pipeline que incluye preprocesamiento de datos (escalado) y el modelo ElasticNet.  \n",
    "Se exploraron combinaciones de hiperparámetros utilizando RandomizedSearchCV. Los parámetros ajustados incluyeron:  \n",
    "- `alpha`: Intensidad de la regularización.  \n",
    "- `l1_ratio`: Proporción entre las penalizaciones L1 y L2.  \n",
    "- `fit_intercept`: Inclusión del intercepto en el modelo.  \n",
    "- `max_iter`: Número máximo de iteraciones.  \n",
    "\n",
    "4. Validación cruzada  \n",
    "Se empleó validación cruzada con 10 folds para evaluar el desempeño del modelo ajustado en múltiples divisiones del conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo ajustado se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE, escalando las variables objetivo para obtener resultados más consistentes.  \n",
    "\n",
    "Resultados: \n",
    "\n",
    "- Validación cruzada  \n",
    "En cada fold de la validación cruzada, se calcularon las métricas R², MSE y MAE para medir el desempeño del modelo en el conjunto de entrenamiento. Los promedios de estas métricas reflejan la consistencia del modelo.  \n",
    "\n",
    "- Conjunto de prueba  \n",
    "El modelo final se evaluó en datos no utilizados durante el entrenamiento, proporcionando métricas que reflejan su capacidad de generalización.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas por ElasticNet: ['AÑO', 'COD_DEP', 'COD_MUN', 'DOCENTES', 'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB', 'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%', 'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS']\n",
      "  Fold 1: R²=0.8356, MSE=0.2252, MAE=0.2801\n",
      "  Fold 2: R²=0.8081, MSE=0.2127, MAE=0.2846\n",
      "  Fold 3: R²=0.8796, MSE=0.1446, MAE=0.2377\n",
      "  Fold 4: R²=0.8072, MSE=0.2013, MAE=0.2395\n",
      "  Fold 5: R²=0.8556, MSE=0.2075, MAE=0.2674\n",
      "  Fold 6: R²=0.7694, MSE=0.2798, MAE=0.2882\n",
      "  Fold 7: R²=0.8348, MSE=0.2024, MAE=0.2463\n",
      "  Fold 8: R²=0.8465, MSE=0.1699, MAE=0.2597\n",
      "  Fold 9: R²=0.8765, MSE=0.1220, MAE=0.2344\n",
      "  Fold 10: R²=0.8281, MSE=0.2277, MAE=0.2819\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8356\n",
      "  Fold 2: 0.8081\n",
      "  Fold 3: 0.8796\n",
      "  Fold 4: 0.8072\n",
      "  Fold 5: 0.8556\n",
      "  Fold 6: 0.7694\n",
      "  Fold 7: 0.8348\n",
      "  Fold 8: 0.8465\n",
      "  Fold 9: 0.8765\n",
      "  Fold 10: 0.8281\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2252\n",
      "  Fold 2: 0.2127\n",
      "  Fold 3: 0.1446\n",
      "  Fold 4: 0.2013\n",
      "  Fold 5: 0.2075\n",
      "  Fold 6: 0.2798\n",
      "  Fold 7: 0.2024\n",
      "  Fold 8: 0.1699\n",
      "  Fold 9: 0.1220\n",
      "  Fold 10: 0.2277\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2801\n",
      "  Fold 2: 0.2846\n",
      "  Fold 3: 0.2377\n",
      "  Fold 4: 0.2395\n",
      "  Fold 5: 0.2674\n",
      "  Fold 6: 0.2882\n",
      "  Fold 7: 0.2463\n",
      "  Fold 8: 0.2597\n",
      "  Fold 9: 0.2344\n",
      "  Fold 10: 0.2819\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8342\n",
      "  Promedio MSE: 0.1993\n",
      "  Promedio MAE: 0.2620\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8242\n",
      "MSE en el conjunto de test: 0.2312\n",
      "MAE en el conjunto de test: 0.2723\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Verificamos si la columna 'GRADUADOS' está en el DataFrame antes de proceder\n",
    "try:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number').drop(columns=['GRADUADOS'])\n",
    "except KeyError:\n",
    "    x_numeric = Graduados_total.select_dtypes(include='number')\n",
    "\n",
    "# Selección de características con ElasticNet\n",
    "scaler = StandardScaler()\n",
    "elasticnet_selector = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "x_scaled = scaler.fit_transform(x_numeric)\n",
    "elasticnet_selector.fit(x_scaled, Graduados_total['GRADUADOS'])\n",
    "\n",
    "# Máscara de características seleccionadas por ElasticNet\n",
    "coeff_mask = np.array([coef != 0 for coef in elasticnet_selector.coef_])\n",
    "selected_features = x_numeric.columns[coeff_mask].tolist()\n",
    "\n",
    "print(\"Características seleccionadas por ElasticNet:\", selected_features)\n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "x = Graduados_total[selected_features]\n",
    "y = Graduados_total['GRADUADOS']\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), selected_features),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Configuramos el pipeline con ElasticNet\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    ElasticNet(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para ElasticNet\n",
    "param_distributions = {\n",
    "    'elasticnet__alpha': uniform(0.01, 10.0),\n",
    "    'elasticnet__fit_intercept': [True, False],\n",
    "    'elasticnet__l1_ratio': uniform(0.0, 1.0),\n",
    "    'elasticnet__max_iter': randint(1000, 5000)\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=10,\n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es predecir la cantidad de graduados (GRADUADOS) utilizando un modelo K-Nearest Neighbors (KNN). Este enfoque no paramétrico se basa en calcular distancias entre puntos para realizar predicciones basadas en los vecinos más cercanos, optimizando el número de vecinos y la métrica de distancia mediante una búsqueda aleatoria de hiperparámetros.\n",
    "\n",
    "Pasos desarrollados: \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico (IQR).  \n",
    "Se dividieron los datos en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Se utilizaron dos tipos de datos:  \n",
    "- Variables numéricas: Indicadores como `DOCENTES`, `MATRICULADOS`, `PIB`.  \n",
    "- Variables categóricas: Incluyen `AREA_CON` y `AÑO`.  \n",
    "Se escaló la variable objetivo GRADUADOS usando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo KNN  \n",
    "Se creó un pipeline que incluyó:  \n",
    "- Preprocesamiento: Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "- Modelo KNN: Predicción basada en los vecinos más cercanos.  \n",
    "\n",
    "3. Ajuste de hiperparámetros  \n",
    "Se exploraron combinaciones de hiperparámetros mediante RandomizedSearchCV, incluyendo:  \n",
    "- `n_neighbors`: Número de vecinos a considerar.  \n",
    "- `weights`: Estrategia de ponderación (`uniform` o basada en la distancia).  \n",
    "- `metric`: Métrica de distancia (`euclidean`, `manhattan`, `minkowski`).  \n",
    "\n",
    "4. Validación cruzada  \n",
    "Se realizó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo ajustado se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados  \n",
    "\n",
    "- Validación cruzada  \n",
    "Se calcularon métricas de desempeño (R², MSE y MAE) en cada fold de la validación cruzada, y se promediaron los resultados para evaluar la consistencia del modelo.  \n",
    "\n",
    "- Conjunto de prueba  \n",
    "El modelo optimizado se evaluó en datos no utilizados durante el entrenamiento, mostrando las siguientes métricas:  \n",
    "  - R²: Medida de la proporción de variabilidad explicada por el modelo.  \n",
    "  - MSE: Magnitud promedio de los errores cuadrados.  \n",
    "  - MAE: Error absoluto promedio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: R²=0.8566, MSE=0.1964, MAE=0.2609\n",
      "  Fold 2: R²=0.7789, MSE=0.2451, MAE=0.2791\n",
      "  Fold 3: R²=0.8534, MSE=0.1761, MAE=0.2654\n",
      "  Fold 4: R²=0.8234, MSE=0.1843, MAE=0.2406\n",
      "  Fold 5: R²=0.8387, MSE=0.2319, MAE=0.2678\n",
      "  Fold 6: R²=0.7164, MSE=0.3442, MAE=0.3197\n",
      "  Fold 7: R²=0.8709, MSE=0.1582, MAE=0.2249\n",
      "  Fold 8: R²=0.8696, MSE=0.1444, MAE=0.2332\n",
      "  Fold 9: R²=0.7920, MSE=0.2053, MAE=0.2577\n",
      "  Fold 10: R²=0.8097, MSE=0.2521, MAE=0.2910\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8566\n",
      "  Fold 2: 0.7789\n",
      "  Fold 3: 0.8534\n",
      "  Fold 4: 0.8234\n",
      "  Fold 5: 0.8387\n",
      "  Fold 6: 0.7164\n",
      "  Fold 7: 0.8709\n",
      "  Fold 8: 0.8696\n",
      "  Fold 9: 0.7920\n",
      "  Fold 10: 0.8097\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.1964\n",
      "  Fold 2: 0.2451\n",
      "  Fold 3: 0.1761\n",
      "  Fold 4: 0.1843\n",
      "  Fold 5: 0.2319\n",
      "  Fold 6: 0.3442\n",
      "  Fold 7: 0.1582\n",
      "  Fold 8: 0.1444\n",
      "  Fold 9: 0.2053\n",
      "  Fold 10: 0.2521\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2609\n",
      "  Fold 2: 0.2791\n",
      "  Fold 3: 0.2654\n",
      "  Fold 4: 0.2406\n",
      "  Fold 5: 0.2678\n",
      "  Fold 6: 0.3197\n",
      "  Fold 7: 0.2249\n",
      "  Fold 8: 0.2332\n",
      "  Fold 9: 0.2577\n",
      "  Fold 10: 0.2910\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8210\n",
      "  Promedio MSE: 0.2138\n",
      "  Promedio MAE: 0.2640\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8046\n",
      "MSE en el conjunto de test: 0.2569\n",
      "MAE en el conjunto de test: 0.2713\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor  # Importamos KNeighborsRegressor\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión KNN\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    KNeighborsRegressor()\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para KNN centrado en encontrar el mejor valor de k\n",
    "param_distributions = {\n",
    "    'kneighborsregressor__n_neighbors': randint(1, 30),          # Número de vecinos (k)\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance'],     # Tipo de ponderación\n",
    "    'kneighborsregressor__metric': ['euclidean', 'manhattan', 'minkowski']  # Métrica de distancia\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de KNN\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # Utiliza todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Arboles de Desicion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Árboles de Decisión. Este modelo no paramétrico permite capturar relaciones complejas y no lineales entre las variables predictoras y la variable objetivo. Además, se realizó una optimización de hiperparámetros mediante RandomizedSearchCV para maximizar el desempeño del modelo.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos de la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Se dividieron los datos en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Los datos se clasificaron en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO  \n",
    "La variable objetivo GRADUADOS fue escalada usando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo de Árboles de Decisión  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas  \n",
    "Modelo Árboles de Decisión DecisionTreeRegressor para realizar predicciones basadas en divisiones jerárquicas de los datos  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Para optimizar el modelo se utilizó RandomizedSearchCV, que realiza una búsqueda aleatoria sobre un espacio definido de hiperparámetros. Los parámetros explorados fueron  \n",
    "max_depth Profundidad máxima del árbol, con valores entre 1 y 20  \n",
    "min_samples_split Mínimo de muestras necesarias para dividir un nodo, valores entre 2 y 20  \n",
    "min_samples_leaf Mínimo de muestras requeridas en una hoja, valores entre 1 y 20  \n",
    "max_features Número de características a considerar al dividir un nodo sqrt, log2 o None  \n",
    "criterion Criterio para medir la calidad de una división squared_error, friedman_mse, absolute_error  \n",
    "\n",
    "Se ejecutaron 50 iteraciones de combinaciones aleatorias de estos hiperparámetros con validación cruzada de 5 folds. El mejor modelo se seleccionó en función de la métrica R².  \n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final ajustado se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "Profundidad máxima del árbol max_depth valor ajustado por el proceso  \n",
    "Muestras mínimas para dividir un nodo min_samples_split valor ajustado  \n",
    "Muestras mínimas en una hoja min_samples_leaf valor ajustado  \n",
    "Criterio para dividir criterion criterio seleccionado  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró el mejor desempeño en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold, con resultados promedio que reflejan la estabilidad y generalización del modelo.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no vistos durante el entrenamiento mostrando  \n",
    "R² Proporción de la variación explicada por el modelo  \n",
    "MSE Magnitud promedio de los errores cuadrados  \n",
    "MAE Error absoluto promedio  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1: R²=0.7192, MSE=0.3848, MAE=0.2795\n",
      "  Fold 2: R²=0.7773, MSE=0.2469, MAE=0.2656\n",
      "  Fold 3: R²=0.8198, MSE=0.2164, MAE=0.2587\n",
      "  Fold 4: R²=0.8000, MSE=0.2087, MAE=0.2396\n",
      "  Fold 5: R²=0.7758, MSE=0.3223, MAE=0.3036\n",
      "  Fold 6: R²=0.7686, MSE=0.2807, MAE=0.2521\n",
      "  Fold 7: R²=0.8705, MSE=0.1586, MAE=0.2192\n",
      "  Fold 8: R²=0.8352, MSE=0.1824, MAE=0.2511\n",
      "  Fold 9: R²=0.8365, MSE=0.1614, MAE=0.2439\n",
      "  Fold 10: R²=0.8175, MSE=0.2417, MAE=0.2526\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.7192\n",
      "  Fold 2: 0.7773\n",
      "  Fold 3: 0.8198\n",
      "  Fold 4: 0.8000\n",
      "  Fold 5: 0.7758\n",
      "  Fold 6: 0.7686\n",
      "  Fold 7: 0.8705\n",
      "  Fold 8: 0.8352\n",
      "  Fold 9: 0.8365\n",
      "  Fold 10: 0.8175\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.3848\n",
      "  Fold 2: 0.2469\n",
      "  Fold 3: 0.2164\n",
      "  Fold 4: 0.2087\n",
      "  Fold 5: 0.3223\n",
      "  Fold 6: 0.2807\n",
      "  Fold 7: 0.1586\n",
      "  Fold 8: 0.1824\n",
      "  Fold 9: 0.1614\n",
      "  Fold 10: 0.2417\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2795\n",
      "  Fold 2: 0.2656\n",
      "  Fold 3: 0.2587\n",
      "  Fold 4: 0.2396\n",
      "  Fold 5: 0.3036\n",
      "  Fold 6: 0.2521\n",
      "  Fold 7: 0.2192\n",
      "  Fold 8: 0.2511\n",
      "  Fold 9: 0.2439\n",
      "  Fold 10: 0.2526\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8021\n",
      "  Promedio MSE: 0.2404\n",
      "  Promedio MAE: 0.2566\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8252\n",
      "MSE en el conjunto de test: 0.2299\n",
      "MAE en el conjunto de test: 0.2520\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor  # Importamos DecisionTreeRegressor\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de Árboles de Decisión\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    DecisionTreeRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para DecisionTreeRegressor (sin 'auto')\n",
    "param_distributions = {\n",
    "    'decisiontreeregressor__max_depth': randint(1, 20),                # Profundidad máxima del árbol\n",
    "    'decisiontreeregressor__min_samples_split': randint(2, 20),        # Mínimo de muestras para dividir un nodo\n",
    "    'decisiontreeregressor__min_samples_leaf': randint(1, 20),         # Mínimo de muestras en una hoja\n",
    "    'decisiontreeregressor__max_features': ['sqrt', 'log2', None],    # Número de características a considerar al buscar la mejor división\n",
    "    'decisiontreeregressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error']  # Criterio de división\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de DecisionTreeRegressor\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # Utiliza todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Ramdom Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Random Forest. Este enfoque de aprendizaje en conjunto permite capturar relaciones complejas y no lineales en los datos mediante la combinación de múltiples árboles de decisión. Para mejorar el rendimiento del modelo, se realizó una optimización de hiperparámetros con RandomizedSearchCV.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo de Random Forest  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo Random Forest RandomForestRegressor para realizar predicciones mediante el promedio de múltiples árboles de decisión.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave en Random Forest. Los parámetros ajustados incluyeron  \n",
    "n_estimators Número de árboles en el bosque, valores entre 100 y 1000.  \n",
    "max_depth Profundidad máxima de los árboles, valores entre 1 y 30.  \n",
    "min_samples_split Mínimo de muestras requeridas para dividir un nodo, valores entre 2 y 20.  \n",
    "min_samples_leaf Mínimo de muestras en una hoja, valores entre 1 y 20.  \n",
    "max_features Número de características consideradas para dividir un nodo sqrt, log2 o None.  \n",
    "bootstrap Si usar muestreo con reemplazo True o sin reemplazo False.  \n",
    "criterion Criterio para medir la calidad de las divisiones squared_error, absolute_error, poisson.  \n",
    "\n",
    "Se ejecutaron 50 combinaciones aleatorias de hiperparámetros con validación cruzada de 5 folds para identificar el modelo óptimo según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "Número de árboles n_estimators valor ajustado.  \n",
    "Profundidad máxima max_depth valor ajustado.  \n",
    "Muestras mínimas para dividir un nodo min_samples_split valor ajustado.  \n",
    "Muestras mínimas en una hoja min_samples_leaf valor ajustado.  \n",
    "Criterio para medir divisiones criterion valor ajustado.  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró un desempeño consistente y efectivo en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold. Los promedios reflejan un buen desempeño del modelo en diferentes particiones de los datos.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no utilizados durante el entrenamiento con los siguientes resultados  \n",
    "R² Proporción de la variación explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.8770, MSE=0.1685, MAE=0.2090\n",
      "  Fold 2: R²=0.8315, MSE=0.1868, MAE=0.2328\n",
      "  Fold 3: R²=0.9173, MSE=0.0994, MAE=0.1859\n",
      "  Fold 4: R²=0.9006, MSE=0.1037, MAE=0.1729\n",
      "  Fold 5: R²=0.9050, MSE=0.1365, MAE=0.2110\n",
      "  Fold 6: R²=0.8781, MSE=0.1480, MAE=0.2083\n",
      "  Fold 7: R²=0.8925, MSE=0.1318, MAE=0.1988\n",
      "  Fold 8: R²=0.9001, MSE=0.1106, MAE=0.2036\n",
      "  Fold 9: R²=0.8570, MSE=0.1411, MAE=0.2222\n",
      "  Fold 10: R²=0.9123, MSE=0.1162, MAE=0.2015\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8770\n",
      "  Fold 2: 0.8315\n",
      "  Fold 3: 0.9173\n",
      "  Fold 4: 0.9006\n",
      "  Fold 5: 0.9050\n",
      "  Fold 6: 0.8781\n",
      "  Fold 7: 0.8925\n",
      "  Fold 8: 0.9001\n",
      "  Fold 9: 0.8570\n",
      "  Fold 10: 0.9123\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.1685\n",
      "  Fold 2: 0.1868\n",
      "  Fold 3: 0.0994\n",
      "  Fold 4: 0.1037\n",
      "  Fold 5: 0.1365\n",
      "  Fold 6: 0.1480\n",
      "  Fold 7: 0.1318\n",
      "  Fold 8: 0.1106\n",
      "  Fold 9: 0.1411\n",
      "  Fold 10: 0.1162\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2090\n",
      "  Fold 2: 0.2328\n",
      "  Fold 3: 0.1859\n",
      "  Fold 4: 0.1729\n",
      "  Fold 5: 0.2110\n",
      "  Fold 6: 0.2083\n",
      "  Fold 7: 0.1988\n",
      "  Fold 8: 0.2036\n",
      "  Fold 9: 0.2222\n",
      "  Fold 10: 0.2015\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8871\n",
      "  Promedio MSE: 0.1343\n",
      "  Promedio MAE: 0.2046\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8793\n",
      "MSE en el conjunto de test: 0.1587\n",
      "MAE en el conjunto de test: 0.2086\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor  # Importamos RandomForestRegressor\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx')\n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de Random Forest\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    RandomForestRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para RandomForestRegressor\n",
    "param_distributions = {\n",
    "    'randomforestregressor__n_estimators': randint(100, 1000),\n",
    "    'randomforestregressor__max_depth': randint(1, 30),\n",
    "    'randomforestregressor__min_samples_split': randint(2, 20),\n",
    "    'randomforestregressor__min_samples_leaf': randint(1, 20),\n",
    "    'randomforestregressor__max_features': ['sqrt', 'log2', None],\n",
    "    'randomforestregressor__bootstrap': [True, False],\n",
    "    'randomforestregressor__criterion': ['squared_error', 'absolute_error', 'poisson']\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de RandomForestRegressor\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,\n",
    "    error_score=np.nan\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Bagging Regressor. Este enfoque de aprendizaje en conjunto combina múltiples estimadores base, en este caso DecisionTreeRegressor, para mejorar la estabilidad y la precisión del modelo. Se realizó una optimización de hiperparámetros con RandomizedSearchCV para maximizar el rendimiento del modelo.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo de Bagging Regressor  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo Bagging Regressor, con DecisionTreeRegressor como estimador base, para realizar predicciones mediante el promedio de múltiples estimadores.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave tanto para Bagging Regressor como para su estimador base DecisionTreeRegressor. Los parámetros ajustados incluyeron  \n",
    "n_estimators Número de estimadores en el conjunto, valores entre 10 y 100.  \n",
    "max_samples Fracción de muestras para entrenar cada estimador, valores entre 0.5 y 1.  \n",
    "max_features Fracción de características para entrenar cada estimador, valores entre 0.5 y 1.  \n",
    "bootstrap Uso de bootstrap True o False.  \n",
    "max_depth Profundidad máxima de los árboles, valores entre 1 y 30.  \n",
    "min_samples_split Mínimo de muestras para dividir un nodo, valores entre 2 y 20.  \n",
    "min_samples_leaf Mínimo de muestras en una hoja, valores entre 1 y 20.  \n",
    "\n",
    "Se ejecutaron 50 combinaciones aleatorias de hiperparámetros con validación cruzada de 5 folds para identificar el modelo óptimo según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "Número de estimadores n_estimators valor ajustado.  \n",
    "Fracción de muestras max_samples valor ajustado.  \n",
    "Fracción de características max_features valor ajustado.  \n",
    "Profundidad máxima max_depth valor ajustado.  \n",
    "Muestras mínimas para dividir un nodo min_samples_split valor ajustado.  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró un desempeño consistente y efectivo en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold. Los promedios reflejan un buen desempeño del modelo en diferentes particiones de los datos.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no utilizados durante el entrenamiento con los siguientes resultados  \n",
    "R² Proporción de la variación explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.8430, MSE=0.2151, MAE=0.2317\n",
      "  Fold 2: R²=0.8335, MSE=0.1845, MAE=0.2395\n",
      "  Fold 3: R²=0.9134, MSE=0.1040, MAE=0.1958\n",
      "  Fold 4: R²=0.8746, MSE=0.1309, MAE=0.1889\n",
      "  Fold 5: R²=0.8877, MSE=0.1614, MAE=0.2195\n",
      "  Fold 6: R²=0.8467, MSE=0.1860, MAE=0.2280\n",
      "  Fold 7: R²=0.8940, MSE=0.1300, MAE=0.2057\n",
      "  Fold 8: R²=0.8900, MSE=0.1218, MAE=0.2135\n",
      "  Fold 9: R²=0.8794, MSE=0.1191, MAE=0.2157\n",
      "  Fold 10: R²=0.8881, MSE=0.1483, MAE=0.2123\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8430\n",
      "  Fold 2: 0.8335\n",
      "  Fold 3: 0.9134\n",
      "  Fold 4: 0.8746\n",
      "  Fold 5: 0.8877\n",
      "  Fold 6: 0.8467\n",
      "  Fold 7: 0.8940\n",
      "  Fold 8: 0.8900\n",
      "  Fold 9: 0.8794\n",
      "  Fold 10: 0.8881\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2151\n",
      "  Fold 2: 0.1845\n",
      "  Fold 3: 0.1040\n",
      "  Fold 4: 0.1309\n",
      "  Fold 5: 0.1614\n",
      "  Fold 6: 0.1860\n",
      "  Fold 7: 0.1300\n",
      "  Fold 8: 0.1218\n",
      "  Fold 9: 0.1191\n",
      "  Fold 10: 0.1483\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2317\n",
      "  Fold 2: 0.2395\n",
      "  Fold 3: 0.1958\n",
      "  Fold 4: 0.1889\n",
      "  Fold 5: 0.2195\n",
      "  Fold 6: 0.2280\n",
      "  Fold 7: 0.2057\n",
      "  Fold 8: 0.2135\n",
      "  Fold 9: 0.2157\n",
      "  Fold 10: 0.2123\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8750\n",
      "  Promedio MSE: 0.1501\n",
      "  Promedio MAE: 0.2151\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8799\n",
      "MSE en el conjunto de test: 0.1579\n",
      "MAE en el conjunto de test: 0.2230\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import BaggingRegressor  # Importamos BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor  # Importamos DecisionTreeRegressor para especificar como base\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de Bagging Regressor con DecisionTreeRegressor como base\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(random_state=42),\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para BaggingRegressor y su estimador base DecisionTreeRegressor\n",
    "param_distributions = {\n",
    "    # Hiperparámetros de BaggingRegressor\n",
    "    'baggingregressor__n_estimators': randint(10, 100),               # Número de estimadores\n",
    "    'baggingregressor__max_samples': uniform(0.5, 0.5),              # Fracción de muestras para entrenar cada estimador\n",
    "    'baggingregressor__max_features': uniform(0.5, 0.5),             # Fracción de características para entrenar cada estimador\n",
    "    'baggingregressor__bootstrap': [True, False],                     # Uso de bootstrap samples\n",
    "    \n",
    "    # Hiperparámetros del estimador base DecisionTreeRegressor\n",
    "    'baggingregressor__estimator__max_depth': randint(1, 30),        # Profundidad máxima del árbol\n",
    "    'baggingregressor__estimator__min_samples_split': randint(2, 20),# Mínimo de muestras para dividir un nodo\n",
    "    'baggingregressor__estimator__min_samples_leaf': randint(1, 20), # Mínimo de muestras en una hoja\n",
    "    'baggingregressor__estimator__max_features': ['sqrt', 'log2', None],  # Número de características a considerar al buscar la mejor división\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de BaggingRegressor y DecisionTreeRegressor\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,            # Para ver el progreso de la búsqueda\n",
    "    error_score=np.nan    # Asigna NaN en caso de error, evitando fallos completos\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo optimizado en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Gradient Boosting Regressor. Este enfoque combina árboles de decisión secuenciales y ajusta cada árbol para corregir los errores de su predecesor. Para optimizar el rendimiento del modelo, se realizó una búsqueda de hiperparámetros con RandomizedSearchCV.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo de Gradient Boosting Regressor  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo Gradient Boosting Regressor, que combina múltiples árboles secuenciales para mejorar el rendimiento predictivo.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave para Gradient Boosting Regressor. Los parámetros ajustados incluyeron  \n",
    "n_estimators Número de árboles en el modelo, valores entre 100 y 1000.  \n",
    "learning_rate Tasa de aprendizaje que controla el impacto de cada árbol, valores entre 0.01 y 0.3.  \n",
    "max_depth Profundidad máxima de los árboles, valores entre 1 y 30.  \n",
    "min_samples_split Mínimo de muestras para dividir un nodo, valores entre 2 y 20.  \n",
    "min_samples_leaf Mínimo de muestras en una hoja, valores entre 1 y 20.  \n",
    "max_features Número de características a considerar al dividir un nodo sqrt, log2 o None.  \n",
    "subsample Fracción de datos para entrenar cada árbol, valores entre 0.5 y 1.  \n",
    "criterion Criterio para medir la calidad de las divisiones friedman_mse, squared_error, absolute_error.  \n",
    "\n",
    "Se ejecutaron 50 combinaciones aleatorias de hiperparámetros con validación cruzada de 5 folds para identificar el modelo óptimo según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "Número de árboles n_estimators valor ajustado.  \n",
    "Tasa de aprendizaje learning_rate valor ajustado.  \n",
    "Profundidad máxima max_depth valor ajustado.  \n",
    "Muestras mínimas para dividir un nodo min_samples_split valor ajustado.  \n",
    "Fracción de datos para cada árbol subsample valor ajustado.  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró un desempeño consistente y efectivo en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold. Los promedios reflejan un buen desempeño del modelo en diferentes particiones de los datos.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no utilizados durante el entrenamiento con los siguientes resultados  \n",
    "R² Proporción de la variación explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.8122, MSE=0.2573, MAE=0.2258\n",
      "  Fold 2: R²=0.8289, MSE=0.1897, MAE=0.2311\n",
      "  Fold 3: R²=0.9024, MSE=0.1172, MAE=0.1992\n",
      "  Fold 4: R²=0.9168, MSE=0.0868, MAE=0.1717\n",
      "  Fold 5: R²=0.8804, MSE=0.1720, MAE=0.2152\n",
      "  Fold 6: R²=0.8550, MSE=0.1759, MAE=0.2257\n",
      "  Fold 7: R²=0.9139, MSE=0.1055, MAE=0.1811\n",
      "  Fold 8: R²=0.8961, MSE=0.1150, MAE=0.2052\n",
      "  Fold 9: R²=0.8701, MSE=0.1282, MAE=0.2234\n",
      "  Fold 10: R²=0.8773, MSE=0.1625, MAE=0.1958\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8122\n",
      "  Fold 2: 0.8289\n",
      "  Fold 3: 0.9024\n",
      "  Fold 4: 0.9168\n",
      "  Fold 5: 0.8804\n",
      "  Fold 6: 0.8550\n",
      "  Fold 7: 0.9139\n",
      "  Fold 8: 0.8961\n",
      "  Fold 9: 0.8701\n",
      "  Fold 10: 0.8773\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2573\n",
      "  Fold 2: 0.1897\n",
      "  Fold 3: 0.1172\n",
      "  Fold 4: 0.0868\n",
      "  Fold 5: 0.1720\n",
      "  Fold 6: 0.1759\n",
      "  Fold 7: 0.1055\n",
      "  Fold 8: 0.1150\n",
      "  Fold 9: 0.1282\n",
      "  Fold 10: 0.1625\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2258\n",
      "  Fold 2: 0.2311\n",
      "  Fold 3: 0.1992\n",
      "  Fold 4: 0.1717\n",
      "  Fold 5: 0.2152\n",
      "  Fold 6: 0.2257\n",
      "  Fold 7: 0.1811\n",
      "  Fold 8: 0.2052\n",
      "  Fold 9: 0.2234\n",
      "  Fold 10: 0.1958\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8753\n",
      "  Promedio MSE: 0.1510\n",
      "  Promedio MAE: 0.2074\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8959\n",
      "MSE en el conjunto de test: 0.1368\n",
      "MAE en el conjunto de test: 0.2055\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Importamos GradientBoostingRegressor\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de Gradient Boosting\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    GradientBoostingRegressor(random_state=42)\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para GradientBoostingRegressor\n",
    "param_distributions = {\n",
    "    'gradientboostingregressor__n_estimators': randint(100, 1000),               # Número de árboles\n",
    "    'gradientboostingregressor__learning_rate': uniform(0.01, 0.3),              # Tasa de aprendizaje\n",
    "    'gradientboostingregressor__max_depth': randint(1, 30),                     # Profundidad máxima del árbol\n",
    "    'gradientboostingregressor__min_samples_split': randint(2, 20),             # Mínimo de muestras para dividir un nodo\n",
    "    'gradientboostingregressor__min_samples_leaf': randint(1, 20),              # Mínimo de muestras en una hoja\n",
    "    'gradientboostingregressor__max_features': ['sqrt', 'log2', None],          # Número de características a considerar al buscar la mejor división\n",
    "    'gradientboostingregressor__subsample': uniform(0.5, 0.5),                   # Submuestreo para cada árbol\n",
    "    'gradientboostingregressor__criterion': ['friedman_mse', 'squared_error', 'absolute_error']  # Criterio de división\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de GradientBoostingRegressor\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,            # Para ver el progreso de la búsqueda\n",
    "    error_score=np.nan    # Asigna NaN en caso de error, evitando fallos completos\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo optimizado en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en XGBoost. Este enfoque combina la eficiencia y precisión del Gradient Boosting con técnicas avanzadas para mejorar la escalabilidad y el rendimiento. Se realizó una búsqueda de hiperparámetros con RandomizedSearchCV para maximizar el desempeño del modelo.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo de XGBoost  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo XGBoost XGBRegressor, una implementación eficiente de Gradient Boosting con capacidad de regularización avanzada y soporte para GPU.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave para XGBRegressor. Los parámetros ajustados incluyeron  \n",
    "n_estimators Número de árboles en el modelo, valores entre 100 y 1000.  \n",
    "learning_rate Tasa de aprendizaje que controla el impacto de cada árbol, valores entre 0.01 y 0.3.  \n",
    "max_depth Profundidad máxima de los árboles, valores entre 1 y 30.  \n",
    "min_child_weight Peso mínimo requerido para las hojas, valores entre 1 y 20.  \n",
    "subsample Fracción de datos para entrenar cada árbol, valores entre 0.5 y 1.  \n",
    "colsample_bytree Fracción de características para cada árbol, valores entre 0.5 y 1.  \n",
    "gamma Parámetro de regularización para la división de nodos, valores entre 0 y 5.  \n",
    "reg_alpha Regularización L1, valores entre 0 y 1.  \n",
    "reg_lambda Regularización L2, valores entre 1 y 2.  \n",
    "booster Tipo de booster gbtree, dart.  \n",
    "tree_method Método para construir los árboles auto, exact, approx, hist, gpu_hist.  \n",
    "\n",
    "Se ejecutaron 50 combinaciones aleatorias de hiperparámetros con validación cruzada de 5 folds para identificar el modelo óptimo según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "Número de árboles n_estimators valor ajustado.  \n",
    "Tasa de aprendizaje learning_rate valor ajustado.  \n",
    "Profundidad máxima max_depth valor ajustado.  \n",
    "Peso mínimo de las hojas min_child_weight valor ajustado.  \n",
    "Fracción de características colsample_bytree valor ajustado.  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró un desempeño consistente y efectivo en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold. Los promedios reflejan un buen desempeño del modelo en diferentes particiones de los datos.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no utilizados durante el entrenamiento con los siguientes resultados  \n",
    "R² Proporción de la variación explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.7988, MSE=0.2756, MAE=0.2318\n",
      "  Fold 2: R²=0.8305, MSE=0.1879, MAE=0.2375\n",
      "  Fold 3: R²=0.9031, MSE=0.1164, MAE=0.1934\n",
      "  Fold 4: R²=0.9074, MSE=0.0967, MAE=0.1751\n",
      "  Fold 5: R²=0.8697, MSE=0.1873, MAE=0.2338\n",
      "  Fold 6: R²=0.8512, MSE=0.1805, MAE=0.2247\n",
      "  Fold 7: R²=0.9101, MSE=0.1102, MAE=0.1871\n",
      "  Fold 8: R²=0.8855, MSE=0.1268, MAE=0.2059\n",
      "  Fold 9: R²=0.8532, MSE=0.1450, MAE=0.2386\n",
      "  Fold 10: R²=0.8775, MSE=0.1622, MAE=0.2061\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.7988\n",
      "  Fold 2: 0.8305\n",
      "  Fold 3: 0.9031\n",
      "  Fold 4: 0.9074\n",
      "  Fold 5: 0.8697\n",
      "  Fold 6: 0.8512\n",
      "  Fold 7: 0.9101\n",
      "  Fold 8: 0.8855\n",
      "  Fold 9: 0.8532\n",
      "  Fold 10: 0.8775\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2756\n",
      "  Fold 2: 0.1879\n",
      "  Fold 3: 0.1164\n",
      "  Fold 4: 0.0967\n",
      "  Fold 5: 0.1873\n",
      "  Fold 6: 0.1805\n",
      "  Fold 7: 0.1102\n",
      "  Fold 8: 0.1268\n",
      "  Fold 9: 0.1450\n",
      "  Fold 10: 0.1622\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2318\n",
      "  Fold 2: 0.2375\n",
      "  Fold 3: 0.1934\n",
      "  Fold 4: 0.1751\n",
      "  Fold 5: 0.2338\n",
      "  Fold 6: 0.2247\n",
      "  Fold 7: 0.1871\n",
      "  Fold 8: 0.2059\n",
      "  Fold 9: 0.2386\n",
      "  Fold 10: 0.2061\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8687\n",
      "  Promedio MSE: 0.1589\n",
      "  Promedio MAE: 0.2134\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8858\n",
      "MSE en el conjunto de test: 0.1502\n",
      "MAE en el conjunto de test: 0.2133\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from xgboost import XGBRegressor  # Importamos XGBRegressor\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de XGBoost\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    XGBRegressor(random_state=42, objective='reg:squarederror')  # Definimos el objetivo por defecto\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para XGBRegressor\n",
    "param_distributions = {\n",
    "    'xgbregressor__n_estimators': randint(100, 1000),               # Número de árboles\n",
    "    'xgbregressor__learning_rate': uniform(0.01, 0.3),              # Tasa de aprendizaje\n",
    "    'xgbregressor__max_depth': randint(1, 30),                     # Profundidad máxima del árbol\n",
    "    'xgbregressor__min_child_weight': randint(1, 20),               # Mínimo peso de la hoja\n",
    "    'xgbregressor__subsample': uniform(0.5, 0.5),                   # Submuestreo para cada árbol\n",
    "    'xgbregressor__colsample_bytree': uniform(0.5, 0.5),             # Submuestreo de características por árbol\n",
    "    'xgbregressor__gamma': uniform(0, 5),                           # Parámetro de regularización\n",
    "    'xgbregressor__reg_alpha': uniform(0, 1),                       # Regularización L1\n",
    "    'xgbregressor__reg_lambda': uniform(1, 1),                      # Regularización L2\n",
    "    'xgbregressor__booster': ['gbtree', 'dart'],                   # Tipo de booster\n",
    "    'xgbregressor__tree_method': ['auto', 'exact', 'approx', 'hist', 'gpu_hist']  # Método de construcción de árbol\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de XGBRegressor\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,            # Para ver el progreso de la búsqueda\n",
    "    error_score=np.nan    # Asigna NaN en caso de error, evitando fallos completos\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo optimizado en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Maquinas de Soporte Vectorial (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Support Vector Regression (SVR). Este enfoque utiliza hiperplanos para encontrar una función de predicción óptima, siendo especialmente efectivo para datos no lineales. Para mejorar el rendimiento, se realizó una búsqueda de hiperparámetros con RandomizedSearchCV.\n",
    "\n",
    "Pasos desarrollados:  \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento 80 por ciento y prueba 20 por ciento.  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo SVR  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo SVR, que utiliza soporte vectorial para encontrar una función de predicción óptima y regularizada.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave para SVR. Los parámetros ajustados incluyeron  \n",
    "C Parámetro de regularización que controla la penalización por errores, valores entre 0.1 y 10.  \n",
    "epsilon Margen de tolerancia dentro del cual no se penalizan los errores, valores entre 0.01 y 1.  \n",
    "kernel Tipo de kernel, como linear.  \n",
    "degree Grado del polinomio para kernel poly, valores entre 2 y 5.  \n",
    "gamma Parámetro para controlar la influencia de cada muestra, valores scale, auto o entre 0.001 y 1.  \n",
    "coef0 Constante para kernels poly y sigmoid, valores entre 0 y 1.  \n",
    "\n",
    "Se ejecutaron 50 combinaciones aleatorias de hiperparámetros con validación cruzada de 5 folds para identificar el modelo óptimo según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se aplicó validación cruzada con 10 folds para evaluar la estabilidad y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue determinado con los siguientes hiperparámetros  \n",
    "C Parámetro de regularización valor ajustado.  \n",
    "epsilon Margen de tolerancia valor ajustado.  \n",
    "kernel Tipo de kernel seleccionado.  \n",
    "gamma Parámetro para controlar la influencia de cada muestra valor ajustado.  \n",
    "\n",
    "El modelo con estos hiperparámetros mostró un desempeño consistente y efectivo en el conjunto de entrenamiento y validación.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon las métricas R², MSE y MAE en cada fold. Los promedios reflejan un buen desempeño del modelo en diferentes particiones de los datos.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo ajustado se evaluó en datos no utilizados durante el entrenamiento con los siguientes resultados  \n",
    "R² Proporción de la variación explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.8146, MSE=0.2541, MAE=0.2890\n",
      "  Fold 2: R²=0.8202, MSE=0.1993, MAE=0.2738\n",
      "  Fold 3: R²=0.8801, MSE=0.1440, MAE=0.2368\n",
      "  Fold 4: R²=0.8091, MSE=0.1993, MAE=0.2344\n",
      "  Fold 5: R²=0.8668, MSE=0.1915, MAE=0.2605\n",
      "  Fold 6: R²=0.7836, MSE=0.2626, MAE=0.2741\n",
      "  Fold 7: R²=0.8202, MSE=0.2203, MAE=0.2504\n",
      "  Fold 8: R²=0.8473, MSE=0.1691, MAE=0.2504\n",
      "  Fold 9: R²=0.8819, MSE=0.1166, MAE=0.2295\n",
      "  Fold 10: R²=0.8342, MSE=0.2196, MAE=0.2697\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8146\n",
      "  Fold 2: 0.8202\n",
      "  Fold 3: 0.8801\n",
      "  Fold 4: 0.8091\n",
      "  Fold 5: 0.8668\n",
      "  Fold 6: 0.7836\n",
      "  Fold 7: 0.8202\n",
      "  Fold 8: 0.8473\n",
      "  Fold 9: 0.8819\n",
      "  Fold 10: 0.8342\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2541\n",
      "  Fold 2: 0.1993\n",
      "  Fold 3: 0.1440\n",
      "  Fold 4: 0.1993\n",
      "  Fold 5: 0.1915\n",
      "  Fold 6: 0.2626\n",
      "  Fold 7: 0.2203\n",
      "  Fold 8: 0.1691\n",
      "  Fold 9: 0.1166\n",
      "  Fold 10: 0.2196\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2890\n",
      "  Fold 2: 0.2738\n",
      "  Fold 3: 0.2368\n",
      "  Fold 4: 0.2344\n",
      "  Fold 5: 0.2605\n",
      "  Fold 6: 0.2741\n",
      "  Fold 7: 0.2504\n",
      "  Fold 8: 0.2504\n",
      "  Fold 9: 0.2295\n",
      "  Fold 10: 0.2697\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8358\n",
      "  Promedio MSE: 0.1976\n",
      "  Promedio MAE: 0.2569\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8288\n",
      "MSE en el conjunto de test: 0.2252\n",
      "MAE en el conjunto de test: 0.2637\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.svm import SVR  # Importamos SVR\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover valores atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de SVR\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para SVR\n",
    "param_distributions = {\n",
    "    'svr__C': uniform(0.1, 10),                         # Parámetro de regularización\n",
    "    'svr__epsilon': uniform(0.01, 1),                   # Epsilon en la función de pérdida\n",
    "    'svr__kernel': ['linear'],  # Tipos de kernel\n",
    "    'svr__degree': randint(2, 5),                       # Grado del polinomio (solo para kernel 'poly')\n",
    "    'svr__gamma': ['scale', 'auto'] + list(np.linspace(0.001, 1, 100)),  # Coeficiente del kernel\n",
    "    'svr__coef0': uniform(0, 1)                         # Independiente del término (solo para kernels 'poly' y 'sigmoid')\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de SVR\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,            # Para ver el progreso de la búsqueda\n",
    "    error_score=np.nan    # Asigna NaN en caso de error, evitando fallos completos\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds (opcional, aunque RandomizedSearchCV ya realiza CV)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo optimizado en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Maquinas de Soporte Vectorial (SVM) con Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es predecir la cantidad de graduados GRADUADOS utilizando un modelo basado en Support Vector Regression (SVR). Este método emplea un enfoque de márgenes para ajustar una función de predicción, siendo adecuado para datos complejos y no lineales. Se optimizaron los hiperparámetros del modelo mediante RandomizedSearchCV.\n",
    "\n",
    "Pasos desarrollados: \n",
    "\n",
    "1. Preparación de los datos  \n",
    "Se eliminaron valores atípicos en la variable GRADUADOS utilizando el rango intercuartílico IQR.  \n",
    "Los datos se dividieron en conjuntos de entrenamiento (80%) y prueba (20%).  \n",
    "Se clasificaron los datos en  \n",
    "Variables numéricas Indicadores como DOCENTES, MATRICULADOS, PIB.  \n",
    "Variables categóricas Incluyen AREA_CON y AÑO.  \n",
    "La variable objetivo GRADUADOS se escaló utilizando RobustScaler para reducir la influencia de valores extremos.  \n",
    "\n",
    "2. Configuración del modelo SVR  \n",
    "Se implementó un pipeline que incluyó  \n",
    "Preprocesamiento Escalado de variables numéricas y codificación one-hot para variables categóricas.  \n",
    "Modelo SVR, que utiliza soporte vectorial para ajustar un modelo basado en márgenes con capacidad para regularizar y manejar relaciones no lineales.  \n",
    "\n",
    "3. Ajuste de hiperparámetros con RandomizedSearchCV  \n",
    "Se utilizó RandomizedSearchCV para explorar combinaciones de hiperparámetros clave para SVR. Los parámetros ajustados incluyeron  \n",
    "C Parámetro de regularización para controlar el margen de tolerancia de errores, valores entre 0.1 y 10.  \n",
    "epsilon Margen de tolerancia que define el rango donde los errores no son penalizados, valores entre 0.01 y 1.  \n",
    "kernel Tipo de kernel que transforma los datos para encontrar un hiperplano, valores poly, rbf y sigmoid.  \n",
    "degree Grado del polinomio aplicado al kernel poly, valores entre 2 y 5.  \n",
    "gamma Parámetro que controla la influencia de las muestras, valores auto, scale o entre 0.001 y 1.  \n",
    "coef0 Constante que afecta los kernels poly y sigmoid, valores entre 0 y 1.  \n",
    "\n",
    "Se realizaron 50 iteraciones de búsqueda aleatoria con validación cruzada de 5 folds para determinar el mejor conjunto de hiperparámetros según la métrica R².\n",
    "\n",
    "4. Validación cruzada  \n",
    "Se llevó a cabo validación cruzada con 10 folds para evaluar la consistencia y generalización del modelo ajustado en el conjunto de entrenamiento.  \n",
    "\n",
    "5. Evaluación del modelo  \n",
    "El modelo final ajustado se evaluó en el conjunto de prueba utilizando métricas como R², MSE y MAE.  \n",
    "\n",
    "Resultados:  \n",
    "\n",
    "Búsqueda de hiperparámetros con RandomizedSearchCV  \n",
    "El modelo óptimo fue identificado con los siguientes hiperparámetros  \n",
    "C Parámetro de regularización valor ajustado.  \n",
    "epsilon Margen de tolerancia valor ajustado.  \n",
    "kernel Tipo de kernel seleccionado.  \n",
    "gamma Influencia de las muestras valor ajustado.  \n",
    "degree Grado del kernel polinómico valor ajustado, si aplica.  \n",
    "\n",
    "El modelo optimizado mostró un desempeño consistente en la validación cruzada y en el conjunto de prueba.\n",
    "\n",
    "Validación cruzada  \n",
    "Se calcularon métricas de desempeño R², MSE y MAE en cada fold, con promedios que reflejan estabilidad y generalización.  \n",
    "\n",
    "Conjunto de prueba  \n",
    "El modelo fue evaluado en datos no vistos durante el entrenamiento, obteniendo los siguientes resultados  \n",
    "R² Proporción de variabilidad explicada por el modelo.  \n",
    "MSE Magnitud promedio de los errores cuadrados.  \n",
    "MAE Error absoluto promedio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "  Fold 1: R²=0.8470, MSE=0.2096, MAE=0.2346\n",
      "  Fold 2: R²=0.8528, MSE=0.1632, MAE=0.2600\n",
      "  Fold 3: R²=0.8542, MSE=0.1751, MAE=0.2485\n",
      "  Fold 4: R²=0.8236, MSE=0.1842, MAE=0.2416\n",
      "  Fold 5: R²=0.8850, MSE=0.1653, MAE=0.2541\n",
      "  Fold 6: R²=0.8111, MSE=0.2293, MAE=0.2712\n",
      "  Fold 7: R²=0.8980, MSE=0.1250, MAE=0.2284\n",
      "  Fold 8: R²=0.8888, MSE=0.1231, MAE=0.2414\n",
      "  Fold 9: R²=0.8788, MSE=0.1197, MAE=0.2463\n",
      "  Fold 10: R²=0.8154, MSE=0.2444, MAE=0.3021\n",
      "\n",
      "Resultados de validación cruzada (escala normalizada):\n",
      "R² scores para cada fold:\n",
      "  Fold 1: 0.8470\n",
      "  Fold 2: 0.8528\n",
      "  Fold 3: 0.8542\n",
      "  Fold 4: 0.8236\n",
      "  Fold 5: 0.8850\n",
      "  Fold 6: 0.8111\n",
      "  Fold 7: 0.8980\n",
      "  Fold 8: 0.8888\n",
      "  Fold 9: 0.8788\n",
      "  Fold 10: 0.8154\n",
      "\n",
      "MSE para cada fold:\n",
      "  Fold 1: 0.2096\n",
      "  Fold 2: 0.1632\n",
      "  Fold 3: 0.1751\n",
      "  Fold 4: 0.1842\n",
      "  Fold 5: 0.1653\n",
      "  Fold 6: 0.2293\n",
      "  Fold 7: 0.1250\n",
      "  Fold 8: 0.1231\n",
      "  Fold 9: 0.1197\n",
      "  Fold 10: 0.2444\n",
      "\n",
      "MAE para cada fold:\n",
      "  Fold 1: 0.2346\n",
      "  Fold 2: 0.2600\n",
      "  Fold 3: 0.2485\n",
      "  Fold 4: 0.2416\n",
      "  Fold 5: 0.2541\n",
      "  Fold 6: 0.2712\n",
      "  Fold 7: 0.2284\n",
      "  Fold 8: 0.2414\n",
      "  Fold 9: 0.2463\n",
      "  Fold 10: 0.3021\n",
      "\n",
      "Promedios de validación cruzada (escala normalizada):\n",
      "  Promedio R²: 0.8555\n",
      "  Promedio MSE: 0.1739\n",
      "  Promedio MAE: 0.2528\n",
      "\n",
      "Resultados en el conjunto de prueba (escala normalizada):\n",
      "R² en el conjunto de test: 0.8673\n",
      "MSE en el conjunto de test: 0.1745\n",
      "MAE en el conjunto de test: 0.2543\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
    "from sklearn.svm import SVR  # Importamos SVR\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Opcional: Suprimir advertencias para una salida más limpia\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargamos el dataset\n",
    "Graduados_total = pd.read_excel('Graduados_total.xlsx') \n",
    "\n",
    "# Función para remover valores atípicos de una columna del DataFrame\n",
    "def remover_atipicos(df, columna):\n",
    "    q1, q3 = df[columna].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    limite_bajo, limite_alto = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    return df[(df[columna] >= limite_bajo) & (df[columna] <= limite_alto)]\n",
    "\n",
    "# Aplicamos la función para remover atípicos en la columna 'GRADUADOS'\n",
    "Graduados_total = remover_atipicos(Graduados_total, 'GRADUADOS')\n",
    "\n",
    "# Definición de variables objetivo y características\n",
    "target = 'GRADUADOS'\n",
    "x = Graduados_total.drop(columns=[target])\n",
    "y = Graduados_total[target]\n",
    "\n",
    "# Seleccionamos características numéricas y categóricas\n",
    "columnas_numericas = [\n",
    "    'DOCENTES',\n",
    "    'MATRICULADOS', 'MATRICULADOS_P', 'POBLACION', 'DEFUNCIONES', 'PIB',\n",
    "    'HOG_CABECERA', 'HOG_CPRD', 'HOG_TOTAL', 'INFLACION ANUAL%',\n",
    "    'INFLACION TOTAL', 'CASOS_V', 'NACIMIENTOS'\n",
    "]\n",
    "columnas_categoricas = ['AREA_CON', 'AÑO']\n",
    "\n",
    "# División de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalamos la variable objetivo 'y' usando RobustScaler\n",
    "scaler_y = RobustScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definimos el preprocesador para los datos numéricos y categóricos\n",
    "preprocesador = make_column_transformer(\n",
    "    (RobustScaler(), columnas_numericas),\n",
    "    (OneHotEncoder(sparse_output=False, handle_unknown='ignore'), columnas_categoricas)\n",
    ")\n",
    "\n",
    "# Creamos el pipeline de preprocesamiento y regresión de SVR\n",
    "pipeline = make_pipeline(\n",
    "    preprocesador,\n",
    "    SVR()\n",
    ")\n",
    "\n",
    "# Definimos el espacio de hiperparámetros para SVR\n",
    "param_distributions = {\n",
    "    'svr__C': uniform(0.1, 10),                         # Parámetro de regularización\n",
    "    'svr__epsilon': uniform(0.01, 1),                   # Epsilon en la función de pérdida\n",
    "    'svr__kernel': ['poly', 'rbf', 'sigmoid'],          # Tipos de kernel\n",
    "    'svr__degree': randint(2, 5),                       # Grado del polinomio (solo para kernel 'poly')\n",
    "    'svr__gamma': ['scale', 'auto'] + list(np.linspace(0.001, 1, 100)),  # Coeficiente del kernel\n",
    "    'svr__coef0': uniform(0, 1)                         # Independiente del término (solo para kernels 'poly' y 'sigmoid')\n",
    "}\n",
    "\n",
    "# Configuramos RandomizedSearchCV para optimizar los hiperparámetros de SVR\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,            # Número de combinaciones a probar\n",
    "    cv=5,                 # Validación cruzada con 5 folds\n",
    "    scoring='r2',         # Métrica de evaluación\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # Utiliza todos los núcleos disponibles\n",
    "    verbose=1,            # Para ver el progreso de la búsqueda\n",
    "    error_score=np.nan    # Asigna NaN en caso de error, evitando fallos completos\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo con la búsqueda aleatoria usando y_train_scaled\n",
    "random_search.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Validación cruzada con 10 folds (opcional, aunque RandomizedSearchCV ya realiza CV)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2_scores, mse_scores, mae_scores = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train), 1):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_fold_train, y_fold_test = y_train_scaled[train_idx], y_train_scaled[test_idx]\n",
    "    \n",
    "    # Entrenamos el mejor modelo encontrado por RandomizedSearchCV\n",
    "    best_model = random_search.best_estimator_\n",
    "    best_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # Realizamos las predicciones\n",
    "    y_fold_pred = best_model.predict(X_fold_test)\n",
    "    \n",
    "    # Calculamos las métricas sobre los valores escalados\n",
    "    r2 = best_model.score(X_fold_test, y_fold_test)\n",
    "    mse = mean_squared_error(y_fold_test, y_fold_pred)\n",
    "    mae = mean_absolute_error(y_fold_test, y_fold_pred)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mse_scores.append(mse)\n",
    "    mae_scores.append(mae)\n",
    "    \n",
    "    print(f\"  Fold {fold}: R²={r2:.4f}, MSE={mse:.4f}, MAE={mae:.4f}\")\n",
    "\n",
    "# Resultados de la validación cruzada\n",
    "print(\"\\nResultados de validación cruzada (escala normalizada):\")\n",
    "print(\"R² scores para cada fold:\")\n",
    "for i, score in enumerate(r2_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "print(\"\\nMSE para cada fold:\")\n",
    "for i, mse in enumerate(mse_scores, 1):\n",
    "    print(f\"  Fold {i}: {mse:.4f}\")\n",
    "print(\"\\nMAE para cada fold:\")\n",
    "for i, mae in enumerate(mae_scores, 1):\n",
    "    print(f\"  Fold {i}: {mae:.4f}\")\n",
    "\n",
    "# Calcular y mostrar los promedios de las métricas\n",
    "print(\"\\nPromedios de validación cruzada (escala normalizada):\")\n",
    "print(f\"  Promedio R²: {np.mean(r2_scores):.4f}\")\n",
    "print(f\"  Promedio MSE: {np.mean(mse_scores):.4f}\")\n",
    "print(f\"  Promedio MAE: {np.mean(mae_scores):.4f}\")\n",
    "\n",
    "# Evaluación del modelo optimizado en el conjunto de prueba usando y_test_scaled\n",
    "r2_test = random_search.best_estimator_.score(X_test, y_test_scaled)\n",
    "y_pred_test_scaled = random_search.best_estimator_.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test_scaled, y_pred_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test_scaled, y_pred_test_scaled)\n",
    "\n",
    "print(\"\\nResultados en el conjunto de prueba (escala normalizada):\")\n",
    "print(f\"R² en el conjunto de test: {r2_test:.4f}\")\n",
    "print(f\"MSE en el conjunto de test: {mse_test:.4f}\")\n",
    "print(f\"MAE en el conjunto de test: {mae_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escoger el mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se presenta una tabla resumen de las métricas obtenidas por los diferentes modelos evaluados. La tabla ha sido generada a partir de un archivo de datos estructurado y formateada visualmente para facilitar la interpretación de los resultados.\n",
    "\n",
    "El código siguiente realiza las siguientes operaciones:\n",
    "1. Carga los datos desde el archivo `Resultados_metricas_modelos.xlsx`.\n",
    "2. Limpia los datos eliminando filas completamente vacías para asegurar que la tabla sea precisa.\n",
    "3. Configura un diseño estético, alternando colores en las filas y resaltando los encabezados.\n",
    "4. Genera una tabla visual utilizando la biblioteca `matplotlib`, ajustando tamaños de fuente y bordes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "# Cargar los datos del archivo\n",
    "file_path = 'Resultados_metricas_modelos.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='Sheet2')\n",
    "\n",
    "# Limpiar y estructurar los datos\n",
    "data_cleaned = data.dropna(how='all')\n",
    "\n",
    "# Configuración de colores\n",
    "header_color = '#40466e'\n",
    "row_colors = ['#f1f1f2', '#ffffff']  # Alternando colores\n",
    "cell_text = data_cleaned.values\n",
    "columns = data_cleaned.columns\n",
    "\n",
    "# Crear figura y eje\n",
    "fig, ax = plt.subplots(figsize=(14, 8))  # Ajustar tamaño según los datos\n",
    "ax.axis('off')  # Ocultar ejes\n",
    "\n",
    "# Crear tabla\n",
    "table = ax.table(\n",
    "    cellText=cell_text,\n",
    "    colLabels=columns,\n",
    "    cellLoc='center',\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "# Estilizar encabezados\n",
    "for (i, j), cell in table.get_celld().items():\n",
    "    if i == 0:\n",
    "        cell.set_facecolor(header_color)\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "    else:\n",
    "        cell.set_facecolor(row_colors[i % len(row_colors)])\n",
    "    # Agregar bordes\n",
    "    cell.set_edgecolor('gray')\n",
    "\n",
    "# Ajustar tamaño de la fuente\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "\n",
    "# Ajustar ancho de columnas\n",
    "for i, column in enumerate(columns):\n",
    "    table.auto_set_column_width(i)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de Gradient Boosting fue seleccionado debido a su destacada capacidad predictiva y precisión, como se refleja en las métricas clave:\n",
    "\n",
    "1. R² promedio en validación cruzada (0.8753): \n",
    "   Esta métrica representa el porcentaje de la variabilidad de los datos que el modelo es capaz de explicar. Un valor cercano a 1 indica un excelente ajuste del modelo. En este caso, un R² de 0.8753 significa que el modelo puede explicar aproximadamente el 87.53% de la variabilidad de los datos en validación cruzada, lo cual es un indicador sólido de su capacidad predictiva. Este alto valor muestra que el modelo capta bien las relaciones subyacentes en los datos.\n",
    "\n",
    "2. MSE promedio en validación cruzada (0.151):  \n",
    "   El Error Cuadrático Medio (MSE) mide el promedio de los errores al cuadrado entre los valores predichos y los valores reales. Un valor más bajo indica que los errores son pequeños y consistentes. En este caso, un MSE de 0.151 refleja que el modelo comete errores pequeños en promedio durante la validación cruzada. Al ser el más bajo (junto con XGBoost), asegura una mayor precisión en las predicciones.\n",
    "\n",
    "3. MAE promedio en validación cruzada (0.2074): \n",
    "   El Error Absoluto Medio (MAE) calcula el promedio de los errores absolutos entre las predicciones y los valores reales. A diferencia del MSE, no penaliza tanto los errores grandes, por lo que es más robusto frente a valores atípicos. En este caso, un MAE de 0.2074 implica que, en promedio, las predicciones del modelo están desviadas en 0.2074 unidades del valor real, lo cual demuestra una buena precisión.\n",
    "\n",
    "4. R² en el conjunto de testeo (0.8959): \n",
    "   En el conjunto de prueba, este R² más alto (89.59%) refuerza la capacidad del modelo para generalizar y capturar la mayoría de la variabilidad de los datos en un conjunto no utilizado durante el entrenamiento. Este valor asegura que el modelo funciona de manera robusta incluso con datos nuevos.\n",
    "\n",
    "5. MSE en el conjunto de testeo (0.1368):  \n",
    "   En el conjunto de testeo, este bajo MSE indica que los errores promedio al cuadrado en las predicciones son mínimos, lo que respalda que el modelo tiene una alta precisión y es capaz de realizar predicciones consistentes.\n",
    "\n",
    "6. MAE en el conjunto de testeo (0.2055):\n",
    "   Finalmente, el MAE de 0.2055 en el conjunto de prueba reafirma que, en promedio, las predicciones se desvían solo 0.2055 unidades del valor real. Este valor es coherente con el bajo MSE, lo que significa que los errores son pequeños y estables.\n",
    "\n",
    "La combinación de un R² alto (que refleja una alta capacidad explicativa) con valores bajos de MSE y MAE (indicativos de errores mínimos y consistentes) confirma que Gradient Boosting es el modelo más adecuado para este problema. No solo captura la relación entre las variables de manera efectiva, sino que también generaliza bien a datos nuevos, lo que lo convierte en una elección confiable y robusta. Además, el costo computacional (tiempo de espera) del modelo Gradient Boosting no es tan alto como otros modelos.\n",
    "\n",
    "En el documento de Interpretaciones, abordaremos mas detalladamente el modelo a profundidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autor: Juan Esteban Londoño Guatibonza, Universidad Externado de Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirigido por: Daniel Godoy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
