{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRYwwQxIap9H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "import json\n",
        "from google.cloud import storage\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud import vision\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseUpload\n",
        "from datetime import datetime\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import google.generativeai as genai\n",
        "import logging\n",
        "import ssl\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import pytesseract  # Si necesitas extraer texto de imágenes\n",
        "\n",
        "# Deshabilitar la verificación de SSL solo para desarrollo (NO recomendado para producción)\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Configurar la clave API de Gemini\n",
        "genai.configure(api_key=\"AIzaSyBm2rRpjFdvQuwKmzFSJ0CA11_0-f95IrE\")\n",
        "# Cargar el tokenizador y el modelo de DistilBERT\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Utiliza BERT-base\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "# Cargar un pipeline para extraer entidades nombradas o conceptos clave (NER)\n",
        "modelo_ner = pipeline(\"ner\", model=\"distilbert-base-uncased\")\n",
        "\n",
        "# Ruta del archivo de credenciales de Google\n",
        "credentials_path = 'C:/Users/acer/Downloads/archivos ia/credentials.json1.json'\n",
        "if not os.path.exists(credentials_path):\n",
        "    raise Exception(f'El archivo de credenciales no se encontró en la ruta: {credentials_path}')\n",
        "\n",
        "# Configurar las credenciales de Google Cloud\n",
        "credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
        "vision_client = vision.ImageAnnotatorClient(credentials=credentials)\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "# Cargar el modelo preentrenado RoBERTa para clasificación de cero disparos (zero-shot)\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"roberta-large-mnli\")\n",
        "\n",
        "# Definir las temáticas personalizadas\n",
        "tematicas_personalizadas = [\n",
        "    \"Matemáticas\", \"Física\", \"Química\", \"Biología\", \"Geometría\", \"Álgebra\", \"Estadística\",\n",
        "    \"Cálculo diferencial\", \"Cálculo integral\", \"Probabilidad\", \"Programación\", \"Machine Learning\",\n",
        "    \"Inteligencia Artificial\", \"Análisis de datos\", \"Desarrollo web\", \"Ciberseguridad\",\n",
        "    \"Sistemas operativos\", \"Redes informáticas\", \"Criptografía\", \"Gestión de bases de datos\",\n",
        "    \"Big Data\", \"Robótica\", \"Nanotecnología\", \"Ingeniería genética\", \"Bioinformática\",\n",
        "    \"Electrónica\", \"Ingeniería civil\", \"Arquitectura\", \"Urbanismo\", \"Energías renovables\",\n",
        "    \"Energía solar\", \"Energía eólica\", \"Astrofísica\", \"Cosmología\", \"Astronomía\", \"Geología\",\n",
        "    \"Ecología\", \"Ciencias ambientales\", \"Meteorología\", \"Oceanografía\", \"Psicología\",\n",
        "    \"Psiquiatría\", \"Sociología\", \"Antropología\", \"Filosofía\", \"Historia\", \"Arqueología\",\n",
        "    \"Lingüística\", \"Literatura\", \"Crítica literaria\", \"Estudios culturales\", \"Estudios de género\",\n",
        "    \"Economía\", \"Microeconomía\", \"Macroeconomía\", \"Econometría\", \"Finanzas\", \"Contabilidad\",\n",
        "    \"Marketing\", \"Gestión de recursos humanos\", \"Gestión de operaciones\", \"Liderazgo\",\n",
        "    \"Emprendimiento\", \"Innovación\", \"Planificación estratégica\", \"Derecho\", \"Derecho internacional\",\n",
        "    \"Derecho penal\", \"Derecho civil\", \"Derecho ambiental\", \"Medicina\", \"Cirugía\", \"Odontología\",\n",
        "    \"Veterinaria\", \"Enfermería\", \"Fisioterapia\", \"Terapia ocupacional\", \"Nutrición\",\n",
        "    \"Educación física\", \"Deportes\", \"Música\", \"Composición musical\", \"Teoría musical\",\n",
        "    \"Interpretación musical\", \"Producción musical\", \"Artes visuales\", \"Pintura\", \"Escultura\",\n",
        "    \"Fotografía\", \"Cine\", \"Animación\", \"Diseño gráfico\", \"Diseño industrial\", \"Moda\",\n",
        "    \"Publicidad\", \"Comunicación\", \"Periodismo\", \"Relaciones públicas\", \"Ética\", \"Moral\"\n",
        "]\n",
        "# Función para clasificar el texto en una temática personalizada\n",
        "def clasificar_tema(texto):\n",
        "    if not texto.strip():\n",
        "        raise Exception(\"El texto para clasificar está vacío.\")\n",
        "\n",
        "    if not tematicas_personalizadas:\n",
        "        raise Exception(\"No hay etiquetas disponibles para la clasificación.\")\n",
        "\n",
        "    try:\n",
        "        resultado = classifier(texto, tematicas_personalizadas)\n",
        "        print(\"Resultado de RoBERTa:\", resultado)  # Debug: Mostrar resultado de RoBERTa\n",
        "        return resultado['labels'][0], resultado['scores'][0]\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error en la clasificación del texto: {str(e)}\")\n",
        "\n",
        "# Función para clasificar usando Gemini (tema y resumen)\n",
        "def clasificar_con_gemini(texto):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    response = model.generate_content(\n",
        "        f\"Por favor, dame el tema especifico, resume el contenido del examen y haz una retroalimentacion pequeña en español. cada seccion debe estar separada y no quiero titulos repetidos : {texto}\"\n",
        "    )\n",
        "\n",
        "    content = response.text.strip()\n",
        "    print(\"Respuesta de Gemini:\", content)  # Debug: Mostrar respuesta de Gemini\n",
        "    return content  # Devuelve solo el contenido (resumen)\n",
        "\n",
        "# Función para analizar el texto y proporcionar retroalimentación\n",
        "def analizar_respuesta(texto):\n",
        "    # Tokenizar el texto\n",
        "    inputs = tokenizer(texto, return_tensors='pt', truncation=True, padding=True)\n",
        "\n",
        "    # Realizar la inferencia\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # Obtener las predicciones\n",
        "    predicciones = torch.argmax(logits, dim=-1).item()  # Convertir a número entero\n",
        "\n",
        "    # Proporcionar retroalimentación básica\n",
        "    retroalimentacion = {\n",
        "        0: \"La respuesta es incompleta. Asegúrate de incluir todos los puntos clave.\",\n",
        "        1: \"La respuesta es correcta, pero podría beneficiarse de ejemplos adicionales.\",\n",
        "        2: \"La respuesta es muy completa. ¡Buen trabajo!\"\n",
        "    }\n",
        "\n",
        "    # Obtener la retroalimentación basada en la predicción\n",
        "    feedback = retroalimentacion.get(predicciones, \"No se pudo determinar la retroalimentación.\")\n",
        "\n",
        "    return feedback\n",
        "\n",
        "\n",
        "# Función para extraer conceptos clave usando NER\n",
        "def extraer_conceptos_clave(texto_respuesta):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    entidades = modelo_ner(texto_respuesta)\n",
        "    conceptos_clave = {ent['word'] for ent in entidades}  # Usamos un set para evitar duplicados\n",
        "    return conceptos_clave\n",
        "\n",
        "# Función para analizar vacíos conceptuales basándose en los conceptos\n",
        "def analizar_vacios_conceptuales(texto_respuesta, conceptos_identificados):\n",
        "    \"\"\"\n",
        "    Analiza si hay vacíos conceptuales en la respuesta del estudiante\n",
        "    basándose en los conceptos clave extraídos.\n",
        "    \"\"\"\n",
        "    vacios = []\n",
        "\n",
        "    # Identificar si algunos conceptos clave no están presentes en la respuesta\n",
        "    if len(conceptos_identificados) < 5:  # Número arbitrario para este ejemplo\n",
        "        vacios.append(\"Falta profundizar en más conceptos clave.\")\n",
        "\n",
        "    feedback = \"La respuesta incluye algunos conceptos clave, pero se recomienda mejorar los siguientes aspectos:\\n\"\n",
        "    feedback += \", \".join(vacios) if vacios else \"No se han identificado vacíos conceptuales significativos.\"\n",
        "\n",
        "    return feedback\n",
        "\n",
        "def generar_retroalimentacion(texto_respuesta):\n",
        "    \"\"\"f\n",
        "    Genera retroalimentación automática sobre los vacíos conceptuales en la respuesta.\n",
        "    \"\"\"\n",
        "    # Extraer los conceptos clave de la respuesta\n",
        "    conceptos_identificados = extraer_conceptos_clave(texto_respuesta)\n",
        "\n",
        "    # Analizar vacíos conceptuales basándose en los conceptos extraídos\n",
        "    retroalimentacion = analizar_vacios_conceptuales(texto_respuesta, conceptos_identificados)\n",
        "\n",
        "    return retroalimentacion\n",
        "# ID del folder en Google Drive donde se subirán los archivos\n",
        "DRIVE_FOLDER_ID = '1QuOJHha_SDZThBqsUAFo3ALvGhWK5loh'\n",
        "\n",
        "# Función para convertir una imagen a texto usando Google Cloud Vision API\n",
        "def convertir_foto_a_texto(image_bytes):\n",
        "    image = vision.Image(content=image_bytes)\n",
        "    response = vision_client.text_detection(image=image)\n",
        "\n",
        "    if response.error.message:\n",
        "        raise Exception(f'Error en la API de Vision: {response.error.message}')\n",
        "\n",
        "    texts = response.text_annotations\n",
        "    texto_extraido = texts[0].description if texts else ''\n",
        "    print(\"Texto extraído de la imagen:\", texto_extraido)  # Debug: Mostrar texto extraído\n",
        "    return texto_extraido\n",
        "def convertir_pdf_a_texto_con_vision(pdf_bytes):\n",
        "    \"\"\"\n",
        "    Usa Google Vision API para extraer texto de un archivo PDF cargado al bucket.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.cloud import storage  # Importar librería para subir al bucket\n",
        "        from google.cloud.vision_v1 import types  # Asegurar que usamos Vision v1\n",
        "        BUCKET_NAME = \"example-bucket-142\"\n",
        "\n",
        "        # Subir PDF al bucket temporalmente\n",
        "        storage_client = storage.Client(credentials=credentials)\n",
        "        bucket = storage_client.bucket(BUCKET_NAME)\n",
        "        blob_name = f\"temp_pdf_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf\"\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_string(pdf_bytes, content_type=\"application/pdf\")\n",
        "\n",
        "        # Configurar fuente GCS para Vision API\n",
        "        gcs_source = {\"uri\": f\"gs://{BUCKET_NAME}/{blob_name}\"}\n",
        "        input_config = types.InputConfig(\n",
        "            gcs_source=types.GcsSource(uri=gcs_source[\"uri\"]),\n",
        "            mime_type=\"application/pdf\"\n",
        "        )\n",
        "\n",
        "        # Solicitar a Vision API\n",
        "        feature = types.Feature(type_=types.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
        "        request = types.AnnotateFileRequest(\n",
        "            input_config=input_config,\n",
        "            features=[feature]\n",
        "        )\n",
        "\n",
        "        # Enviar solicitud de batch\n",
        "        response = vision_client.batch_annotate_files(requests=[request])\n",
        "        texto_extraido = \"\"\n",
        "\n",
        "        # Procesar la respuesta\n",
        "        for file_response in response.responses:\n",
        "            if file_response.error.message:\n",
        "                raise Exception(f\"Vision API Error: {file_response.error.message}\")\n",
        "            for page_response in file_response.responses:\n",
        "                texto_extraido += page_response.full_text_annotation.text\n",
        "\n",
        "        # Eliminar el archivo temporal del bucket\n",
        "        blob.delete()\n",
        "\n",
        "        return texto_extraido.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error al extraer texto del PDF con Google Vision: {str(e)}\")\n",
        "\n",
        "\n",
        "# Función para subir un archivo a Google Drive\n",
        "def subir_archivo_a_drive(nombre_archivo, contenido, mimetype):\n",
        "    archivo_bytes = io.BytesIO(contenido.encode('utf-8') if mimetype == 'text/plain' else contenido)\n",
        "    file_metadata = {\n",
        "        'name': nombre_archivo,\n",
        "        'parents': [DRIVE_FOLDER_ID]\n",
        "    }\n",
        "    media = MediaIoBaseUpload(archivo_bytes, mimetype=mimetype)\n",
        "\n",
        "    try:\n",
        "        uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        print(f'Archivo subido a Drive: {uploaded_file.get(\"id\")}')  # Debug: Confirmar subida\n",
        "        return uploaded_file.get(\"id\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f'Error al subir el archivo a Google Drive: {str(e)}')\n",
        "\n",
        "# Variable global para el contador\n",
        "contador_archivos = 1  # Se puede inicializar desde 1 o cargar desde un archivo externo\n",
        "\n",
        "# Función para generar un nombre de archivo secuencial\n",
        "def generar_nombre_archivo_secuencial():\n",
        "    global contador_archivos\n",
        "    nombre_archivo = f'Analisis Fidea #{contador_archivos} - {datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt'\n",
        "    contador_archivos += 1  # Incrementar el contador para el próximo archivo\n",
        "    return nombre_archivo\n",
        "\n",
        "# Función para guardar el texto en Google Drive con el nombre secuencial\n",
        "def guardar_texto_en_drive(texto):\n",
        "    file_name = generar_nombre_archivo_secuencial()  # Usar la nueva función para generar el nombre\n",
        "    file_metadata = {\n",
        "        'name': file_name,\n",
        "        'parents': [DRIVE_FOLDER_ID],\n",
        "        'mimeType': 'text/plain'\n",
        "    }\n",
        "\n",
        "    media = MediaIoBaseUpload(io.BytesIO(texto.encode('utf-8')), mimetype='text/plain')\n",
        "\n",
        "    try:\n",
        "        uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        print(f'Archivo de texto guardado en Drive: {uploaded_file.get(\"id\")}')  # Debug: Confirmar subida\n",
        "        return uploaded_file.get('id')\n",
        "    except Exception as e:\n",
        "        raise Exception(f'Error al subir el archivo de texto a Drive: {str(e)}')\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "# Ruta para la página principal\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Endpoint para subir imagen capturada desde la cámara\n",
        "@app.route('/upload', methods=['POST'])\n",
        "def upload_image():\n",
        "    if 'image' not in request.form:\n",
        "        return jsonify({'error': 'No se recibió ninguna imagen'}), 400\n",
        "\n",
        "    image_data = request.form['image']\n",
        "\n",
        "    if image_data.startswith('data:image/jpeg;base64,'):\n",
        "        image_data = image_data.split(',')[1]\n",
        "\n",
        "    try:\n",
        "        image_bytes = base64.b64decode(image_data)\n",
        "\n",
        "        nombre_archivo = f'captured_image_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.jpg'\n",
        "        file_metadata = {\n",
        "            'name': nombre_archivo,\n",
        "            'parents': [DRIVE_FOLDER_ID]\n",
        "        }\n",
        "        media = MediaIoBaseUpload(io.BytesIO(image_bytes), mimetype='image/jpeg')\n",
        "\n",
        "        uploaded_file1 = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        app.logger.debug(f'Archivo de imagen subido: {uploaded_file1.get(\"id\")}')\n",
        "\n",
        "        # Extraer texto de la imagen\n",
        "        texto_extraido = convertir_foto_a_texto(image_bytes)\n",
        "\n",
        "        # Clasificar el texto usando las temáticas personalizadas\n",
        "        tema_roberta, score_roberta = clasificar_tema(texto_extraido)\n",
        "        resumen_gemini = clasificar_con_gemini(texto_extraido)  # Solo se guarda el resumen\n",
        "         # Analizar respuesta y proporcionar retroalimentación\n",
        "        feedback = analizar_respuesta(texto_extraido)\n",
        "        vacios_feedback = generar_retroalimentacion(texto_extraido)\n",
        "\n",
        "        # Guardar el texto y el tema clasificado en Google Drive\n",
        "        texto_final = (f\"{texto_extraido}\\n\\n\"\n",
        "               f\"Tema Detectado por RoBERTa: {tema_roberta} (Score: {score_roberta:.2f})\\n\"\n",
        "               f\"Resumen Detectado por Gemini: {resumen_gemini}\\n\"\n",
        "               f\"feedback: {feedback}\\n\"\n",
        "               f\"Vacios Conceptuales: {vacios_feedback}\\n\")  # Llama a la función para obtener vacíos conceptuales\n",
        "\n",
        "\n",
        "\n",
        "        archivo_texto_id = guardar_texto_en_drive(texto_final)\n",
        "\n",
        "        return jsonify({\n",
        "            'message': 'Imagen procesada exitosamente',\n",
        "            'file_id': uploaded_file.get('id'),\n",
        "            'archivo_texto_id': archivo_texto_id,\n",
        "            'texto_extraido': texto_final,\n",
        "            'tema_roberta': tema_roberta,\n",
        "            'resumen_gemini': resumen_gemini,\n",
        "            'feedback': feedback,\n",
        "            'vacios_feedback': vacios_feedback\n",
        "\n",
        "\n",
        "           # Incluir la retroalimentación en la respuesta JSON\n",
        "        }), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        app.logger.error(f'Error al procesar la imagen: {str(e)}')\n",
        "        return jsonify({'error': f'Error al procesar la imagen: {str(e)}'}), 500\n",
        "\n",
        "def extraer_texto_de_pdf(pdf_bytes):\n",
        "    texto = \"\"\n",
        "    try:\n",
        "        with fitz.open(stream=pdf_bytes, filetype=\"pdf\") as pdf:\n",
        "            for pagina in pdf:\n",
        "                texto += pagina.get_text()\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error al procesar el PDF: {str(e)}\")\n",
        "    return texto\n",
        "\n",
        "# Endpoint para subir archivos desde el computador\n",
        "@app.route('/upload_file', methods=['POST'])\n",
        "def upload_file():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No se recibió ningún archivo'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    try:\n",
        "        file_bytes = io.BytesIO(file.read())\n",
        "        app.logger.debug(f\"Procesando archivo: {file.filename}, Tipo: {file.content_type}\")\n",
        "\n",
        "        # Subir archivo a Google Drive\n",
        "        file_metadata = {\n",
        "            'name': file.filename,\n",
        "            'parents': [DRIVE_FOLDER_ID]\n",
        "        }\n",
        "        media = MediaIoBaseUpload(file_bytes, mimetype=file.content_type)\n",
        "\n",
        "        uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "        app.logger.debug(f'Archivo subido a Google Drive: {uploaded_file.get(\"id\")}')\n",
        "\n",
        "        # Reiniciar el puntero del archivo\n",
        "        file_bytes.seek(0)\n",
        "\n",
        "        # Procesar el archivo\n",
        "        texto_extraido = \"\"\n",
        "        if file.content_type.startswith('image/'):\n",
        "            app.logger.debug(\"El archivo es una imagen, extrayendo texto...\")\n",
        "            texto_extraido = convertir_foto_a_texto(file_bytes.getvalue())\n",
        "        elif file.content_type == 'application/pdf':\n",
        "          texto_extraido = convertir_pdf_a_texto_con_vision(file_bytes.getvalue())\n",
        "          if not texto_extraido.strip():\n",
        "            raise Exception(\"El PDF no contiene texto reconocible.\")\n",
        "\n",
        "\n",
        "\n",
        "        # Clasificar el texto usando las temáticas personalizadas\n",
        "        tema_roberta, score_roberta = clasificar_tema(texto_extraido)\n",
        "        resumen_gemini = clasificar_con_gemini(texto_extraido)  # Solo se guarda el resumen\n",
        "\n",
        "        # Generar retroalimentación\n",
        "        feedback = analizar_respuesta(texto_extraido)\n",
        "        vacios_feedback = generar_retroalimentacion(texto_extraido)\n",
        "\n",
        "        # Guardar el texto en Google Drive\n",
        "        texto_final = (f\"{texto_extraido}\\n\\n\"\n",
        "                       f\"Tema Detectado por RoBERTa: {tema_roberta} (Score: {score_roberta:.2f})\\n\"\n",
        "                       f\"Resumen Detectado por Gemini: {resumen_gemini}\\n\"\n",
        "                       f\"Feedback: {feedback}\\n\"\n",
        "                       f\"Vacios Conceptuales: {vacios_feedback}\\n\")\n",
        "\n",
        "        archivo_texto_id = guardar_texto_en_drive(texto_final)\n",
        "\n",
        "        return jsonify({\n",
        "            'message': 'Archivo procesado exitosamente',\n",
        "            'file_id': uploaded_file.get('id'),\n",
        "            'archivo_texto_id': archivo_texto_id,\n",
        "            'texto_extraido': texto_final,\n",
        "            'tema_roberta': tema_roberta,\n",
        "            'resumen_gemini': resumen_gemini,\n",
        "            'feedback': feedback,\n",
        "            'vacios_feedback': vacios_feedback\n",
        "        }), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        app.logger.error(f'Error al procesar el archivo: {str(e)}')\n",
        "        return jsonify({'error': f'Error al procesar el archivo: {str(e)}'}), 500\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n",
        "\n",
        "\n",
        "    ################################################################################################################################################################\n",
        "\n",
        "    #AUTORES: Paula Andrea Guzman Cañas y Carlos Eduardo Galvis Salamanca\n",
        "\n",
        "    # Universidad Externado de Colombia\n",
        "\n",
        "    # Revisado por: Daniel Godoy"
      ]
    }
  ]
}